
# 第一章

## 七个伟大思想

1. 抽象简化设计
2. 加速经常性事件
3. 并行
4. 流水线
5. 预测
6. 存储层次
7. 通过冗余提高可靠性

## 性能

### 度量性能

1. 挂钟时间 响应时间 运行时间
包括:磁盘访问,内存访问,IO操作和os开销
2. cpu时间
只在cpu上花费的时间,包括用户cpu时间和系统cpu时间(操作系统帮用户执行的任务)

### 计算

1. cpu时间=cpu周期数 x 周期时间=周期数/cpu频率
2. cpu周期数=程序指令数 x 指令平均时钟周期数(CPI)
3. cpu时间=指令数 x CPI / cpu频率

注:
- cpu主频提高和周期数增加不成正比
- ISA称为指令集架构,相同指令集架构的CPI也不一定相同
- 在比较性能强弱时使用比值,强的做分子

### 计算-2

不同种类的指令的CPI不同,所以采用分层计算

eg.
![[Pasted image 20241015185809.png]]

## 影响程序性能的因素

| 硬件或软件指标  | 影响什么         |
| -------- | ------------ |
| 算法       | IC(指令数),cpi  |
| 编程语言     | 同上           |
| 编译器      | 同上           |
| 指令系统体系结构 | 指令数,时钟频率,cpi |

## 功耗墙

由于功耗限制
当功耗上升时,无法再降低硬件的电压和散出足够的热量
从而摩尔定律受到影响
现在处于后pc时代

# 第二章

除浮点数外的指令集:
[[计算机组成原理-en.pdf#page=278&selection=0,3,14,19|基本指令集]]

各种指令格式:
[[riscv基本指令集.pdf#page=1&selection=1,1,2,43|指令格式]]


## 指令类型

1. 运算指令
	1. 算数运算
	2. 逻辑运算
2. 数据传输
	1. load
	2. store
	3. 外设IO读取
3. 控制指令
	1. 条件分支
	2. 无条件分支

## 指令格式

### 概述

1. 指令固定为32位,四个字节
2. 操作码固定7位
3. 操作数长度25位
	1. 寄存器
	2. 内存
	3. 立即数

### R型指令 op rd rs1 rs2 opcode=0110011

![[Pasted image 20240920151101.png]]
包括:	
1. add,sub
2. sll,srl,sra
3. or,and,xor
4. slt,sltu(小于置位指令)

funct3和funct7区分具体指令
### I型指令 op rd rs imm 

![[Pasted image 20240920152324.png]]

包括:
1. addi,subi
2. slli,srli,srai
3. ori,andi,xori
4. slti,sltui
5. lb,lh,lw,lbu,lhu
6. ==jalr== jalr,x0,0(x1) 跳转到x1的地址,将pc+4存到x0,即舍弃pc+4

立即数范围: $-2^{11}$ ~ $2^{11}-1$


### S型指令 op rs1 imm(rs2)

![[Pasted image 20240920153828.png]]

包括:
	sb
	sh
	sw
	
为什么要把立即数拆开?
和R型指令保持一致
### SB型指令 op rs1 rs2 Label

![[Pasted image 20241015192827.png]]
第11位和12位的设计和S型指令保持一致
12位做最高位保持符号
最低位不存储,补0,因为指令的地址都是4的倍数,最后两位肯定为0,但是为了支持16位指令,仅做最低为0的保证.

包括:
	beq
	bne
	bge
	blt
	bltu
	bgeu

可跳转范围: $2^{-12}$  ~  $2^{12}-1$
即:+-4K的指令数

至于标签如何转化为地址,由处理器进行转化:pc+imm * 2
注:imm * 2 是做低位补0的处理

### J型指令

无条件跳转指令

![[Pasted image 20241015193619.png]]

仅有:jal指令

jal x1,Label

寻址范围:$-2^{20}$ ~ $2^{20}-1$
即:+-1M

跳转至Label,将pc+4存入x1

### U型指令 op rd imm

![[Pasted image 20241015194140.png]]

包括:lui,auipc

lui将立即数存入rd高20位,低12位清零
auipc将pc+imm<<12存入rd

## 寄存器分类

1. x0 0 zero
2. x1 返回地址 ra
3. x2 栈指针 sp
4. x3 全局指针 gp
5. x4 线程指针 tp
6. x5-x7,x28-x31 临时寄存器 (t0-t6)
7. x8 帧指针(函数栈帧末尾的指针)
8. x8,x9,x18-x27 保存寄存器 (s0-s11)
9. x10-x11 函数参数,返回值 a0,a1
10. x12-x17 函数参数 (a2-a7)

## 字符串

ascii
unicode

一个字符占用一个字节
字符串占有连续的存储空间

## 伪指令

```risc-v
mv rs1,rs2
j Label->jal x0,Label
jr x1->jalr x0,0(x1)
li x5 0xDEADBEEF(lui)
la x5,Label ->auipc
```

## 多线程指令 条件读取和存储

[[计算机组成原理-preview#多任务|多任务]]


# 第三章 ALU硬件和乘法运算

## ALU和加减法

通过电路和数据选择器来实现加减与或运算

overflow检测是否溢出，看操作数和结果的符号位就行

最高位加法器的输出set连接到最低位less的输入来实现slt指令

饱和算法:上溢取最大值,下溢取最小值

减法:a+b=a+~b+1

## 乘法

用到的部件:加法器,移位器,存储部分积,乘数和被乘数的寄存器

> 过程:
> 部分积初始化为全0
> 每个周期中顺序执行下列操作,执行乘数位数次
> 1. 判断乘数最低位是0还是1,若0不做操作,进行下一步.若1将被乘数加到部分积上,进行下一步
> 2. 被乘数左移一位,相当于×2
> 3. 乘数右移一位,高位补0

==注:==
上述操作中,被乘数需要左移32位,所以要用64位寄存器保存被乘数,同时用64位寄存器保存部分积,但是乘数只需要32位寄存器就行

 并行执行乘法操作:
 将乘数和积放在同一个寄存器中,如果乘数位为1,被乘数和乘数移位,被乘数加到积上.同时积寄存器增加到65位来保存加法器的进位,ALU缩减到32位ALU

## 浮点数

[[IEEE-754]]

根据浮点数计算的顺序:

加法:
1. 比较指数
2. 对齐
3. 加
4. 规格化
5. 舍入

乘法:
1. 指数相加,即对于IEEE-754中,指数位相加减去偏置量
2. 做乘法,按照可保存的小数位数进行保存
3. 规格化乘积
4. 检测是否溢出(指数位)
5. 规格化有多余的位数,进行舍入
6. 判断符号

## 浮点数寄存器

32个浮点数寄存器
f0~f31,f0没有硬连接到常数0
每个寄存器都有64位,单精度浮点数存储在低32位中
全部只用于浮点数操作

## 浮点数运算指令

在常规指令前加上f,再在后面加上.s或者.d表示单精度还是双精度

1. fadd.s fsub.s fmul.s fdiv.s fsqrt.s
2. fadd.d fsub.d fmul.d fdiv.d fsqrt.d
3. feq.s flt.s fle.s 等于 小于 小于等于
4. feq.d flt.d fle.d
	1. 比较结果0或1放在整数目的寄存器中 `feq.s x5,f1,f2 x5=1 if f1==f2`
	2. 再使用beq和bne来跳转
5. flw fld 取字,取双字
6. fsw fsd
7. B.cond 条件分支指令(了解)


# 第四章 CPU数据和控制通路

指令的执行都分为五个阶段：
1. 取指令IF
2. 译码和读寄存器 ID
3. 进行ALU计算相关数据 EX
4. 读取和写入内存 MEM
5. 写回寄存器WB
## 单周期处理器

### 数据通路设计

1. 取指令 从指令内存IMEM中取出指令
2. 译码和寄存器读取 解析指令，并在RF中读取寄存器内容 RF如下图所示：
![[Pasted image 20241016111941.png]]
其中左侧从上到下依次对应rs1,rs2,rd,要写入到rd的数据,右侧分别为rs1和rs2的具体值,当指令中没有rs2时,读出为乱码,数据随后流入ALU
3. ALU进行计算,根据不同的指令类型比如add rd rs1 rs2,addi rd rs1 rs2,lw rd,imm(rs1),sw rs2,imm(rs1)等,进行rs1和rs2或者rs1与imm的计算
4. 读内存和写内存,没什么好说的
5. 写回寄存器,要选择写回rd的是哪个数据,是ALU计算产生的还是从内存中读取到的数据

注意用到立即数的指令需要用到ImmGen立即数产生单元

为了满足branch指令,还需要用到ALU的zero值判断rs1和rs2是否相等,另外需要计算出pc + imm * 2 ,因此需要加上一个移位器和加法器

### 控制信号设计

根据指令的不同,设置不同的信号值来执行不同的操作,比如寄存器写,ALUSrc等,详见下表:
其中ALUOP是为了简化ALU输入而设计的

控制信号有两种实现办法:
1. 由输入的opcode和fun3和fun7,通过真值表和化简设计门电路来实现电路功能
2. 使用存储型控制器:只读存储器ROM,根据读入的opcode和fun3和fun7产生地址,在ROM对应地址处查询指令类型,输出对应控制信号

![图片](附件/Pasted%20image%2020241030190325.png)

因此整体的数据通路和控制通路设计如下:
![[Pasted image 20241018150350.png]]

### 最小周期时间

最小周期时间由指令中需要用到最多的功能部件的指令决定,在上面的指令中,lw决定了cpu周期的最小值应该大于等于lw指令所需的时间

## 多周期处理器

将cpu周期降到一个时间最长的操作需要的时间,比如读内存需要的200ps.
这样每个指令需要若干个cpu周期执行,比如lw需要5个cpu周期
但是在每个cpu周期内还是只有一个部件在执行工作,效率依旧不高,因此我们设计流水线处理器结构

## 流水线

### 相关概念

> 流水线级数

执行完一条指令需要哪几个步骤,如五级流水线:

1. IF:instruction fetch
2. ID:instruction decode & register read
3. EX: execute operation or caculate
4. MEM: access memory
5. WB:write back to register

> 加速比

取决于吞吐量的提高

### 五级流水线各步骤用到的部件

1. pc,IM,adder
2. RF
3. ALU
4. DM
5. RF

如何解决用到两次RF的问题?
RF所需的时间仅为100ps,所以在一个cpu周期(200ps)中,使用前半周期写,后半周期读
这样设计的目的是:保证读取数据可以读到正确的数据

既然同时有5条指令在执行,那如何解决一条指令执行过程中所需要的数据可能被修改的问题?
——在每两个功能部件之间加上寄存器,一共有四个,以相邻两个功能部件的名称命名:IF/ID,ID/EX,EX/MEM,MEM/WB

整体结构:

![[Pasted image 20241025144544.png]]
### 结构冒险

一个结构同时被两个操作用到,比如lw和IF都需要用到内存单元,所以我们设计指令内存单元IMEM和数据内存单元DMEM

### 数据冒险

数据冒险主要由指令执行过程中的数据依赖产生

如:
![](附件/Pasted%20image%2020241030193358.png)

在第二条指令的ID阶段需要读取x19寄存器的值,但是在第二个周期时第一条指令还在ID阶段,x19的值需要在第五个周期的前半周期结束后才是正确值.

有两个解决办法:
1. 阻塞(stall)
	1. 在sub取指后持续执行ID,直到读取到正确数据,阻塞两个周期
	2. 上图中的bubble只是一种形式化的表示,实际中sub在两个冒泡中仍在执行,只是一直在ID而已
2. 旁路Bypassing(前递Forwarding)
	1. 既然读寄存器的目的是送往ALU计算,那么即使读出来的数据不对,只要输入给ALU的数据对就好了,因此我们可以直接将上一条指令的ALU输出作为下一条指令的ALU输入,这称为EX旁路
	2. 如下图所示:
	3. 但是对于lw指令,如果下面指令和lw指令产生数据相关,那么需要在MEM阶段结束后读取到的数据才是对的,此时把MEM的数据在写回之前直接送给ALU,但是仍然需要耽误一个周期,详见下2图
![](附件/Pasted%20image%2020241030195330.png)

![](附件/Pasted%20image%2020241030195636.png)
### 控制冒险

来源于branch指令,在beq指令中,只有在第三个周期结束时才判断出是否分支,计算出pc+imm * 2,第四个周期才执行将分支地址写回pc的操作,因此有指令可能是被错误执行的

解决方法:
1. 阻塞:beq后的指令不执行,一直等到beq执行完成写回pc操作再取指
2. 预测:预测后面会不会发生分支
	1. 静态预测
	2. 动态预测

### 解决冒险之前的准备

在发生数据回流的情况时会出现问题,比如:第一条指令WB需要写回rd,此时rd的值已经是第四条指令的rd值,因此我们需要保存rd的值到流水线寄存器中

对于控制信号:
ALU控制器不变
IF和ID不需要信号
EX需要 ALUsrc ALUcontrol
MEM需要 MemWrite MemRead Branch PCsrc
WB需要 MemToReg RegWrite

设计为:控制器放在ID阶段产生控制信号,在每个流水线寄存器中添加控制信号存储
![](附件/Pasted%20image%2020241030202056.png)

### 数据冒险解决

> EX旁路

方法:ALU的输入多一个,来自于ALU的输出,多加一个控制信号选择输入信号的来源
控制信号的产生?即选择ALU输出作为输入的条件?
1. 下一条指令的rs1或rs2与当前指令的rd相同
	1. 由EX旁路的图可知,这个过程发生在针对当前指令的第三周期,此时rd存储在EX/MEM寄存器,下一条指令的rs1和rs2存储在ID/EXE中
2. 同时要保证rd不等于0,因为x0永远为0,依赖x0的没有意义,不需要给x0传送数据
3. 同时这条指令应该是需要写入rd寄存器的指令,它的RegWrite信号为1,这个信号在EX/MEM中

因此可以得到以下公式:
选择ALU输出作为输入,当且仅当:
EX/MEM rd=ID/EX rs1 or EX/MEM rd=ID/EX rs2
and
EX/MEM rd!=x0
and
EX/MEM RegWrite=1

> MEM旁路

方法:再给ALU输入加一个

条件:
1. 第一条指令的rd是第二条指令的rs1或rs2
2. 根据此时指令间的关系,得:

MEM/WB rd=ID/EX rs1 or MEM/WB rd = ID/EX rs2
and
MEM/WB rd!=x0
and
MEM/WB RegWrite=1

![](附件/Pasted%20image%2020241030203503.png)

![](附件/Pasted%20image%2020241030203515.png)

上述情况存在一些问题:
```risc-v
add x1,x2,x3
add x1,x1,x4
add x5,x1,x6
```
![](附件/5affef0fed7f89420878548a4ea11b42.jpg)

如上图,这里同时满足两个旁路的条件,本不该使用MEM旁路的也使用了MEM旁路,因此我们需要修改MEM旁路的条件:

1. 满足前面提到的MEM旁路的条件
2. 不满足前面提到的EX旁路的条件

即:

![](附件/e1ba03a1e8e3e15aee1d3432d35b91d9.jpg)
完整旁路图:

![](附件/Pasted%20image%2020241030205648.png)

### 数据冒险中的另一个问题：load指令

如下图所示，因为load指令的值在第四周期结束后才能得到，而若有一条与他相邻的指令在EX阶段也就是第四周期开始时要用到此值，则必须阻塞一个周期，同时用到MEM旁路：

![](附件/Pasted%20image%2020241105172208.png)

这种情况下的旁路和阻塞条件：

1. ID/EXE rd=IF/ID rs1 or ID/EXE rd=IF/ID rs2
2. ID/EXE MemRead=1(保证是load指令)
3. ID/EXE rd!=x0

> 为什么要判断ID/EXE和IF/ID寄存器而不是EX/MEM和ID/EXE寄存器?

因为要向ID/EXE中写入清零的控制信号,以来使当前的and指令成为nop信号

阻塞的实现:

1. 写进ID/EXE的控制信号清零
2. 第三个周期结束后不写IF/ID寄存器(and的下一条指令丢弃)
3. 不写PC(下一条指令仍是and)

这里需要新加一个冒险检测单元来控制IF/ID是否写,PC是否写,选择写进ID/EXE的信号为0

### 控制冒险解决

控制冒险示例如下图:
![](附件/Pasted%20image%2020241105173434.png)

根据上面的硬件设计,只有MEM阶段结束后,PC才能得到要跳转到的地址,所以这其中有三条指令执行错误,所以解决办法是遇到beq指令就将接下来的三条指令清空(注意flush和stall的区别),等到MEM结束后再开始执行正确的指令.但是这样效率太低了,因此我们可以把判断分支和写回pc的操作提前.

> 提前到EX阶段

这很容易,只要把加法器和选择器提前一个阶段执行就行,这样可以少浪费一个周期

> 提前到ID阶段

pc+imm * 2和pc+4因为可以并行执行所以不受影响,往前提就是了,但是怎么判断rs1和rs2是否相等?我们原来是在EX阶段结束后根据ALU的zero结果来判断的,但是提前到ID阶段后没有ALU计算了.此时可以使用ID阶段读出的rs1和rs2进行异或来判断rs1和rs2是否相等(相同为0相反为1)

这样在ID阶段结束后第三条指令的IF取出的就是正确的地址,但是仍然浪费了一个周期.

> 上面的方法看似只浪费了一个周期很完美,但是!!!

如果上下文中有数据相关和数据冒险:
![](附件/Pasted%20image%2020241105174538.png)
需要再添加到ID的旁路(之前只有EX到EX或MEM到EX的旁路)

还有一种情况,如果比较的两个寄存器一个是前一条指令的ALU结果,另一个是前两条指令的load结果:
![](附件/Pasted%20image%2020241105174724.png)
需要阻塞一个周期

还有极端的情况:load指令后紧接着数据相关的beq指令:
![](附件/Pasted%20image%2020241105174848.png)
此时需要阻塞两个周期

看吧,还是浪费周期了~!!!!

怎么办?能不能把预测提前到IF阶段,即取指令的时候就知道会不会发生分支?有!动态预测!

### 动态预测

把预测提前到IF阶段看似很好,但是有一个问题:IF阶段不知道指令的类型,怎么办?

解决方法:增加一个缓冲区,表中存储已经发生过的分支指令

>一位预测器

| PC   | 指令  | 状态位  | 预测地址 |
| ---- | --- | ---- | ---- |
| addr | beq | 0(1) |      |
|      |     |      |      |
这个表是在cpu中用一个额外的硬件实现的,具体的工作流程是:在取指令之前,在表中根据指令地址搜索,若表中存在该地址,那么若状态位为1,则跳转到相应预测地址;若状态位为0,则不跳转,执行pc+4;若该过程中存在错误,则修改错误并把状态位修改为相应0或1
若表中不存在该分支指令,则向表中写入该分支指令,按照不发生分支处理.再根据错误与否改变

> 两位预测器

上述一位预测器有一个问题:即若每个循环中的判断在第一次和最后一次总是错误.

解决方法:两位预测器,即将状态位改为2位                                                                                                                                                     

| pc  | 指令  | 状态位(两位)00 01 10 11 | 分支地址 |
| --- | --- | ------------------ | ---- |
|     |     |                    |      |

00 01->不发生分支
10 11->发生分支

具体工作:

在00和11状态下,如果预测正确,则状态码保持当前状态;如果预测错误,则状态码向中间移动一位(00->01,11->10)
在01和10状态下,按照预测结果移动
eg 01:预测不发生分支,若实际未发生分支,则01变为00;若实际发生分支,则变为10

### 异常和中断 另一种控制冒险

异常:软件引起

1. syscall
2. undefined opcode

中断:硬件引起,内存,网卡等

在发生中断或者异常后,要保存发生异常的指令的地址,以及发生中断的原因,然后转移到异常处理程序进行处理

为了实现上述过程,增加一个SEPC(supervisor exception program counter)寄存器,来保存发生中断的指令的地址.增加一个SCAUSE寄存器,来保存发生中断的原因.risc-v的异常处理程序入口统一为:`0x0000 0000 1C09 0000`

> SCAUSE寄存器有64位,每一位对应一种异常种类,若发生某种异常,则将对应位置1.因为所有异常处理程序的入口一样,所以系统异常处理程序先读取SCAUSE寄存器

> intel处理器采用向量中断法处理异常.内存中在系统初始化维护一个表,表中存储异常对应的中断向量号和对应的错误处理程序入口地址

异常处理有三个结果:
1. 异常处理成功:返回源程序继续执行
2. 异常无法处理,系统强行结束程序
3. 死机

### 异常和中断的硬件处理

![](附件/Pasted%20image%2020241105195851.png)

发生中断后,要将当前执行的指令和后续指令清空,同时保证前面的指令正确执行.
IF.Flush信号清除位于IF阶段的指令,ID.Flush和冒险检测单元的stall信号或后清空ID阶段的指令,EX.Flush信号清除位于EX阶段的指令,pc新增一个输入来源.

# 第五章 存储层次

## 存储层次

cpu:寄存器
cpu cache:SRAM
主存(内存):DRAM
固态存储:ssd,flash

计算机设计从以cpu为中心->以存储为中心

## 局部性原理

### 时间局部性

访问过的数据可能再次访问如循环控制变量等

### 空间局部性

访问过的数据附近的数据也可能被访问,如数组

## 存储器

### SRAM 静态随机访问存储器

RAM:random access memory

SRAM是以MOSS管的导通和截止来分别表示0/1,一个存储单元需要有6个moss管,集成度低,单位价格高

### DRAM

DRAM只有单个moss管,以电容上有无电荷来表示0/1
因为读取电容的电荷会导致电容放电,破坏原有状态,所以称为**破坏性读**,所以读的过程中包含着写
因为电容充电较慢,所以DRAM的速度较慢
因为只有一个moss管,所以集成度较高,价格比较便宜.
**动态**:因为电容存在电阻,所以每2ms一个单元的电荷就会漏完,每2ms需要刷新,通过读DRAM来实现,若刷新时正好有来自cpu的读请求,以刷新为高优先级

随机的含义:读写时间和读写位置无关

DRAM的高级技术:
1. 突发模式:同一行中相邻数据进行传输,这样只有第一个数据传输时需要若干个周期,其后的若干数据仅需一个周期
2. DDR(double data rate):在一个cpu的上升沿和下降沿都进行传输
3. QDR:DDR的输入和输出分开
4. ROW buffer
5. 同步DRAM
6. banking![](附件/e5c03b0fd6a158390ea0ebe9a4869deb_720.jpg)

### 固态硬盘

采用flash storage
分为:
1. NOR flash:按位读写,用于嵌入式系统
2. NAND flash:按块存储

每个单元只能写1000次
一旦一个单元损坏,整个损坏
为了保持寿命,采用均衡写算法,延长flash存储器的寿命

### 机械硬盘

磁道
扇区
柱面

读取过程:
1. 寻道
2. 旋转
3. 读取

在使用磁盘之前要先指定文件存储系统

一个扇区中包括:数据(512字节等),id,纠错码,gaps等

平均读写时间:
1. 队列延时
2. 寻道时间(随机,取平均)
3. 旋转时间(随机,取平均)
4. 数据传送时间
5. 控制器时间

通过操作系统调度算法可以减少寻道时间
硬盘里加入cache
智能硬盘控制器预测要读的扇区

## Cache Memory

### 术语

cpu向cache发送要求数据的地址,若cache中此地址,称为命中(hit),若没有找到,称为缺失(miss)
cache内容是mem内容的映像
cache和mem以块(block)为单位传输数据(或者叫做行(line))
内存地址划分为3个部分:
tag index offset
分别代表:tag,块地址,块内字节地址

### 主存cache映射方法

最简单的方式是直接映射

块地址=主存块号%cache块数

因为主存中可能有多个地址被映射到同一个块号,因此地址需要额外的tag位来标识cache存储的具体是哪一块

又因为启动时cache中的数据都是无效的,因此为了判断cache中是否是有效数据,需要增加有效位

因此根据地址寻找cache中内容的过程是:
1. 通过块地址定位到块
2. 判断有效位是否为1
3. 通过tag定位到具体是主存的哪个具体地址
4. 通过块内地址确定要读取的字节

**区分字节地址和字地址**
字节地址:通过地址找到一个字节
字地址:通过地址找到一个字

### 增大块的大小的优势与劣势

由于空间局部性,可知道可以增大命中率
但是因为cache的总容量一定,所以块的数量变少,意味着更多的主存地址会映射到同一块,这样会导致频繁调度,导致块污染,意味着需要更多的时间传输地址

软件调度算法:
早启动:一旦取到所需数据,流水线继续流动(IM中效果较好)


###  Cache 缺失

#### 读取

1. 根据index找到cache中的块
2. 若有效位为1则看tag是否相等判断是否命中，0则不命中
3. 在不命中的情况下，cpu的流水线需要停顿
4. 从下一层层次结构中读取数据

#### 写回内存

因为写入cache后cache和mem的内容不同,要采用一些策略处理

一.命中情况(cache中有所需地址)

1. 写直达法:既写cache又写mem,保持块内容的一致性,但是增大了写回开销.可以采用添加buffer的方法,将要写入mem的数据存入buffer,但是当buffer满了之后仍需阻塞
2. 写回法:先只更新cache的内容,同时cache要增加一个脏位.当一个脏位为1的cache块需要被替换时,再进行写回mem的操作

二.不命中情况(cache中无所需地址)

1. 写分配法:将mem中的块调入cache,然后采用写回法
2. 非写分配:直接对mem进行操作,采用写直达法

### 性能评测

#### 使用cpi评测

内存stall周期=程序中指令数\*缺失率\*缺失代价

注意i-cache对每条指令而言都要访问

#### 使用平均访存时间(AMAT)

amat=hit time+miss rate\*miss penalty

### 组相联cache

#### 全相联

一个内存地址可以映射到cache中任何一个块,即无index位,这样的方式缺失率低,但是硬件代价大

tag包含了全部的主存块号,tag的比较硬件大,需要块数个比较器

#### 组相联

将cache分为若干个组,每个组中包含若干个缓存行
从mem到cache使用直接映射,组内采用全相联,使用组内块数个比较器
组号=主存块号 mod 组数
使用最近最少使用算法进行组内替换

### 多级cache

主要注意性能计算:

cpi=原cpi + 一级cache缺失率 \* 一级cache缺失开销 + 二级cache缺失率 \* 二级cache缺失开销

### 分块技术

体现在矩阵运算中,使用类似分块矩阵的技术,可以提高cache命中率
## 虚拟机,虚拟地址

虚拟机使用主存作为硬盘的cache
程序共享一个主存,但是为每一个程序分配一个独立的虚拟地址空间,装载其常用的代码和数据数据,这个虚拟地址空间和其他程序隔离
每个虚拟地址空间的大小通常为$2^{48}$字节
cpu和操作系统要进行虚拟地址和物理地址的转化,在虚拟机的概念中,块被称为页,块缺失被称为页错误

### 实现的原理

1. 程序运行时由操作系统通过装载器将代码从disk装载到mem中,仅装载一部分代码,以page为单位,page的大小通常为4k字节,采用全相联映射
2. 虚拟空间一部分由mem构成一部分由disk构成
3. 当指令执行的时候,需要将虚拟空间转化为物理空间

### 虚拟地址和物理地址转换

1. 虚拟地址:页号+页内地址
2. 物理地址:页号+页内地址
3. 两者的页内地址相同,仅需将虚拟页号(vpn)转化为物理页号(ppn)

关于虚拟页号和物理页号的转化方式:
在内存里维护一个页表,每个进程有自己独有的页表,操作系统为进程建立这个页表,页表中维护vpn到ppn的映射.
页表行的个数和虚拟空间的页数相同,ppn可能是物理页号也可能是硬盘信息

### 页表的内容

| VPN | PPN | v   | dirty | R   |
| --- | --- | --- | ----- | --- |
|     |     |     |       |     |
v是有效位,代表页是否在内存中,若不在则发生缺页故障,缺页故障处理程序将页从disk调往主存,同时修改ppn和有效位
dirty为脏位,用于采用写回策略来修改disk内容
R位用于实现LRU算法,若该页表项最近被访问过则修改为1,否则修改为0.替换时搜索第一个引用位为0的页表项并替换,每过一段时间自动把R位全部清0
PPN,v,dirty,R共称为页表项(PTE)

### TLB

因为访问一次内存,需要先访问页表来完成虚拟地址到物理地址的转化,再访问实际物理地址获得实际数据(即需要两次内存访问),速度过慢,所以可以采用类似cache的思想,在cpu中引入一个cache用于存储PTEs,称为TLB,存储最近要访问的页表项(一般存储16-512个页表项).
若缺失再从mem中请求然后放入TLB中.采用类似cache映射的三种方式

### cache缺失类型 3c缺失

1. 冷启动缺失 compulsory 第一次启动
2. 容量缺失 capacity 全相联映射
3. 冲突缺失 conflict 直接映像和组相联缺失

## 校验和可靠性评估

