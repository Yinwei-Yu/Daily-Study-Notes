# 操作系统

## 进程管理

### 进程抽象

- **进程定义**：
  - **机器状态**：地址空间、寄存器（PC、栈指针）、打开文件等。
  - **进程状态**：
    - **运行（Running）**：正在执行指令。
    - **就绪（Ready）**：可运行但未被调度。
    - **阻塞（Blocked）**：等待I/O等事件。
- **进程生命周期**：
  - **创建**：加载代码、分配内存、初始化栈和堆。
  - **终止**：父进程调用`wait()`回收资源，子进程进入僵尸状态。
- **进程调度**：
  - **上下文切换**：保存寄存器状态，切换内核栈。
  - **进程列表（PCB）**：存储进程状态、PID、父进程等信息（如xv6的`proc`结构体）。
- **关键概念**：
  - **时间分片（Time Sharing）**：通过快速切换进程实现CPU虚拟化。
  - **空间分片（Space Sharing）**：资源按空间划分（如磁盘块）。

#### 进程API

- **核心系统调用**：
  - **`fork()`**：创建子进程，复制父进程地址空间。
    - 子进程返回0，父进程返回子进程PID。
    - 不确定性：子进程和父进程执行顺序由调度器决定。
  - **`wait()`**：父进程等待子进程结束，保证执行顺序。
  - **`exec()`**：加载新程序覆盖当前进程（如`execvp()`运行`/bin/ls`）。
- **关键机制**：
  - **Shell工作原理**：`fork()` + `exec()` + `wait()`，支持重定向和管道。
  - **文件描述符管理**：子进程关闭标准输出后打开文件，实现输出重定向。
- **进程控制**：
  - **信号处理**：`kill()`发送信号（如SIGINT终止进程）。
  - **用户权限**：普通用户仅控制自身进程，超级用户（root）拥有全权限。
- **工具与调试**：
  - **`ps`、`top`、`kill`**：查看进程状态、资源占用和终止进程。
  - **`sched_setaffinity()`**：绑定进程到指定CPU（Linux）。

### 有限直接执行机制

- **核心机制**：
  - **直接执行协议**：用户程序直接运行，但通过陷阱（Trap）限制特权操作。
  - **特权模式**：
    - **用户模式**：受限操作（如I/O）触发陷阱，切换到内核模式。
    - **内核模式**：执行特权指令（如配置陷阱表、启动定时器）。
  - **陷阱处理**：
    - **系统调用**：通过陷阱号指定服务（如`open()`）。
    - **陷阱表初始化**：系统启动时注册陷阱处理程序。
- **上下文切换**：
  - **定时器中断**：强制剥夺CPU控制权，触发调度。
  - **保存与恢复**：保存当前进程寄存器到内核栈，加载目标进程状态。
- **并发控制**：
  - **中断屏蔽**：处理中断时禁用其他中断，避免竞态条件。
  - **锁机制**：保护内核数据结构（后续并发章节详细讨论）。
- **性能优化**：
  - **LDE协议**：减少模式切换开销，平衡性能与控制。
  - **计时器精度**：现代系统上下文切换耗时约微秒级（使用`Imbench`测量）。

### 调度算法（FIFO、SJF、STCF、RR）知识点总结

#### **1. 基本概念**

- **调度核心问题**：  
  - 设计策略以优化性能指标（如周转时间、响应时间）。  
  - 解决公平性与效率的权衡。  
- **工作负载假设**（逐步放宽）：  
  - 所有作业运行时间相同、同时到达、无I/O、已知运行时等（初始假设不现实，但用于推导算法）。  

#### **2. 调度算法**

- **FIFO（先进先出）**：  
  - **规则**：按到达顺序执行作业。  
  - **优点**：简单易实现。  
  - **缺点**：导致**护航效应**（长作业阻塞短作业，平均周转时间长）。  
  - **示例**：三个作业（100s、10s、10s）的平均周转时间为 110s。  

- **SJF（最短作业优先）**：  
  - **规则**：优先运行剩余时间最短的作业。  
  - **优点**：优化周转时间（理论最优，假设作业同时到达）。  
  - **缺点**：非抢占式，无法处理作业动态到达（导致护航效应）。  
  - **示例**：短作业提前运行，平均周转时间显著降低。  

- **STCF（最短完成时间优先）**：  
  - **规则**：SJF的抢占式版本，新作业到达时重新选择最短剩余时间的作业。  
  - **优点**：解决作业动态到达问题，进一步优化周转时间。  
  - **示例**：长作业被短作业抢占，平均周转时间改善为 50s。  

- **RR（轮转调度）**：  
  - **规则**：每个作业分配固定时间片，轮流执行。  
  - **优点**：优化响应时间，适合交互式任务。  
  - **缺点**：周转时间差（作业被“拉伸”执行）。  
  - **关键参数**：时间片长度需平衡响应时间与上下文切换开销。  

#### **3. 调度指标**

- **周转时间（Turnaround Time）**：  
  - \( T_{\text{turnaround}} = T_{\text{completion}} - T_{\text{arrival}} \)。  
  - SJF/STCF 优化此指标，RR 表现差。  
- **响应时间（Response Time）**：  
  - \( T_{\text{response}} = T_{\text{firstrun}} - T_{\text{arrival}} \)。  
  - RR 优化此指标，SJF/STCF 表现差。  

#### **4. 实际挑战与解决方案**

- **I/O操作的处理**：  
  - 将作业的CPU突发（Burst）视为独立任务，利用I/O等待时间运行其他作业。  
  - **示例**：交替执行CPU突发和I/O操作，提高CPU利用率（图7.9）。  
- **未知作业长度**：  
  - 需要动态预测（后续章节的MLFQ算法）。  

#### **5. 算法对比与权衡**

- **公平性 vs. 性能**：  
  - RR追求公平但牺牲周转时间；SJF/STCF追求性能但牺牲响应时间。  
- **时间片选择**：  
  - 短时间片提高响应速度，但增加上下文切换开销（需**摊销成本**）。  

#### **6. 扩展问题（作业示例）**

- **如何配置调度器**：  
  - 相同作业长度下，SJF与FIFO的周转时间相同。  
  - RR与SJF响应时间相同的条件：所有作业长度相同且时间片≥作业长度。  
- **响应时间趋势**：  
  - SJF中，作业越长，响应时间越差（需等待前面长作业完成）。  
  - RR的最坏响应时间公式：\( T_{\text{worst}} = (N-1) \times \text{时间片} \)。  

---  
**总结**：  
调度算法需在周转时间与响应时间间权衡。FIFO简单但低效，SJF/STCF优化周转但需预知作业长度，RR适合交互任务但牺牲周转性能。实际系统中需结合I/O处理与动态预测，MLFQ等高级算法进一步解决未知作业长度问题。

### 多级反馈队列（MLFQ）调度算法知识点总结

#### **1. 基本概念与目标**

- **核心目标**：  
  - 优化周转时间（类似SJF/STCF，但无需预知作业长度）。  
  - 最小化交互式作业的响应时间（类似轮转调度）。  
- **核心思想**：通过历史行为动态调整作业优先级，实现“学习型调度”。

#### **2. MLFQ规则**

- **基本规则**：  
  - **规则1**：高优先级作业优先运行（若A的优先级 > B，则A运行）。  
  - **规则2**：同优先级作业按轮转（RR）调度。  
  - **规则3**：新作业进入最高优先级队列（默认初始优先级最高）。  
  - **规则4**（改进后）：作业用完当前队列的时间配额后降级（无论是否中途释放CPU）。  
  - **规则5**：周期性地将所有作业提升至最高优先级（解决饥饿问题）。  

#### **3. 关键机制**

- **动态优先级调整**：  
  - 交互式作业（频繁释放CPU）保持高优先级。  
  - CPU密集型作业（长时间占用CPU）逐渐降级到低优先级队列。  
- **时间配额（Allotment）**：  
  - 每个队列分配的时间配额决定作业何时降级。  
  - 初始实现中，配额等于时间片；改进后配额累计使用。  
- **周期性优先级提升**：  
  - 参数`S`（提升周期）需平衡交互响应与长作业公平性（如默认1秒）。  

#### **4. 问题与解决方案**

- **饥饿问题**：  
  - 低优先级长作业可能长期无法运行。  
  - **解决方案**：规则5周期性提升所有作业优先级。  
- **用户“欺骗”调度器**：  
  - 通过频繁I/O操作重置时间配额以保持高优先级。  
  - **解决方案**：规则4改为累计时间配额，不因I/O重置。  
- **参数调优挑战**：  
  - 队列数量、时间片长度、`S`值等需经验调整（避免“巫毒常量”）。  

#### **5. 实现细节与变体**

- **队列配置**：  
  - 高优先级队列时间片短（如10ms），低优先级队列时间片长（如100ms）。  
  - 示例：Solaris TS调度类使用60个队列，时间片逐步增加。  
- **系统优化**：  
  - 部分系统为内核任务保留最高优先级。  
  - 支持用户建议（如`nice`命令调整优先级）。  

#### **6. 优势与适用场景**

- **优势**：  
  - 结合短作业优先与轮转调度的优点。  
  - 动态适应作业行为变化（如CPU密集型转为交互式）。  
- **应用**：BSD、Solaris、Windows等操作系统的基础调度器。  

#### **7. 示例与验证**

- **示例1**：长作业逐步降级至最低队列。  
- **示例2**：短作业抢占长作业，近似SJF行为。  
- **示例3**：交互式作业通过I/O保持高优先级。  

#### **8. 扩展问题（作业）**

- 如何配置MLFQ模拟纯轮转调度？  
  - 设置所有队列优先级相同，时间片一致。  
- 如何防止用户“欺骗”？  
  - 启用改进后的规则4（累计时间配额）。  
- 参数计算：若最高队列时间片为10ms，需每200ms提升优先级（保证长作业获得至少5% CPU）。  

---  
总结：MLFQ通过多级队列、动态优先级调整和周期性重置，平衡了响应时间与周转时间，是实际系统中广泛采用的高效调度算法。

### **彩票调度（Lottery Scheduling）知识点总结**

#### **1. 核心概念**

- **彩票（Tickets）**：  
  - 表示进程对CPU时间的分配比例。例如，进程A持有75张票，B持有25张，则A占75%的CPU时间概率。
  - 彩票总数决定调度概率，随机选取中奖彩票决定运行进程。

- **随机性优势**：  
  - 避免传统算法（如LRU）的极端情况性能问题。
  - 实现简单、轻量级且高效，无复杂状态跟踪。
  - 短期可能偏离比例，长期趋向公平。

---  

#### **2. 关键机制**

- **调度流程**：  
  1. 统计所有进程的彩票总数。
  2. 生成随机数（0到彩票总数-1）。
  3. 遍历进程列表，累加彩票直至超过随机数，选中对应进程。

- **代码实现示例**：  

  ```c
  int winner = getrandom(0, totaltickets);
  int counter = 0;
  for each process in list {
      counter += process->tickets;
      if (counter > winner) break;
  }
  ```

  - 若进程按彩票数降序排列，可减少遍历次数。

- **高级机制**：  
  - **货币（Currency）**：允许用户自定义内部彩票分配，系统转换为全局彩票。  
    *例如：用户A分配500票给两个进程，实际各占全局50票。*
  - **彩票转让（Transfer）**：进程临时转移彩票（如客户端-服务器场景）。  
  - **彩票通胀（Inflation）**：信任环境下，进程可动态调整自身彩票数。

---  

#### **3. 优缺点**

- **优点**：  
  - 实现简单，无复杂状态管理。
  - 天然支持动态进程加入，仅需更新全局彩票总数。
  - 避免优先级反转等传统问题。
- **缺点**：  
  - 短期公平性不足（需长时间运行趋近比例）。
  - 不适用于需严格保证比例的实时系统。

---  

### **步幅调度（Stride Scheduling）知识点总结**

---  

#### **1. 核心概念**

- **步幅（Stride）**：  
  - 步幅 = 固定大数（如10,000） / 进程彩票数。  
    *例如：A（100票）步幅为100，B（50票）步幅为200。*
  - **通行值（Pass）**：进程每次运行后累加步幅，记录全局进度。

- **调度规则**：  
  - 每次选择通行值最小的进程运行，更新其通行值。
  - 长期精确保证CPU分配比例。

---  

#### **2. 调度示例**

- 进程A（步幅100）、B（步幅200）、C（步幅40）初始通行值均为0。
- **调度顺序**：  
  - 第一轮：A(0)→B(0)→C(0) → C(40)→C(80)→A(100)→C(120)→C(160)→C(200)  
  - 结果：C运行5次，A运行2次，B运行1次，符合彩票比例（250:100:50）。

---  

#### **3. 优缺点**

- **优点**：  
  - 确定性公平，长期严格符合比例。
  - 无随机性波动。
- **缺点**：  
  - 需维护全局通行值状态，新进程加入需谨慎初始化通行值。
  - 实现复杂度高于彩票调度。

---  

### **Linux完全公平调度（CFS）知识点总结**

---  

#### **1. 核心机制**

- **虚拟运行时间（vruntime）**：  
  - 进程实际运行时间按权重（权重与优先级相关）缩放后累计。  
    *公式：vruntime_i += (weight_0 / weight_i) * runtime_i*  
  - 调度时选择vruntime最小的进程。

- **时间片动态调整**：  
  - **sched_latency**：目标调度周期（如48ms），按进程数分配时间片。  
    *例如：4个进程 → 每个时间片12ms。*
  - **min_granularity**：最小时间片（如6ms），避免过多上下文切换。

---  

#### **2. 优先级与权重**

- **Nice值**：范围-20（高优先级）到19（低优先级），默认0。
- **权重表**：将Nice值映射为权重（如Nice=-5对应3121，Nice=0对应1024）。
- **时间片计算**：  
  ```time_slice_k = (weight_k / Σweight_i) * sched_latency```  
  *例如：A（权重3121）、B（1024） → A占75%时间，B占25%。*

---  

#### **3. 高效数据结构**

- **红黑树（Red-Black Tree）**：  
  - 存储可运行进程，按vruntime排序。  
  - 插入、删除、查找操作时间复杂度为O(log n)，适用于大规模进程。
  - 休眠进程移出树，唤醒时重置vruntime为当前树中最小值，避免饥饿。

---  

#### **4. 处理休眠进程**

- **唤醒策略**：  
  - 休眠进程唤醒后，vruntime设为当前运行进程的最小值，避免长期休眠进程垄断CPU。
  - 牺牲短期公平性，换取整体系统响应。

---  

#### **5. 优缺点**

- **优点**：  
  - 高效且可扩展，适用于高负载场景。
  - 动态调整时间片，平衡公平性与性能。
  - 支持优先级（Nice值），灵活分配资源。
- **缺点**：  
  - 短期休眠进程可能无法获得公平份额。
  - 实现复杂，依赖精确的vruntime计算和红黑树维护。

---  

### **综合对比**

| **调度算法**     | **公平性**       | **实现复杂度** | **适用场景**                     | **核心机制**               |
|------------------|------------------|----------------|----------------------------------|----------------------------|
| **彩票调度**     | 概率公平（长期） | 低             | 动态环境、快速决策               | 随机选择中奖彩票           |
| **步幅调度**     | 确定公平（长期） | 中             | 需严格比例保证的实时系统         | 步幅累计与最小通行值选择   |
| **CFS**          | 近似公平（短期） | 高             | 通用系统（如Linux）、高并发负载  | 虚拟运行时间与红黑树管理   |

---  

### **扩展知识点**

1. **CFS的调度周期**：  
   - 通过定时器中断（如1ms）检查当前进程是否用完时间片。
   - 若未用完但存在更低vruntime进程，可能触发抢占。

2. **权重表的数学特性**：  
   - Nice值每增加1，CPU份额下降约10%（权重按指数衰减设计）。

3. **历史背景**：  
   - 彩票调度由Waldspurger提出，灵感源于资源分配的随机公平性。
   - CFS由Ingo Molnár设计，取代Linux O(1)调度器，解决多核扩展性问题。

---  

以上为彩票调度、步幅调度及Linux CFS的核心知识点总结，涵盖机制、实现、优缺点及对比，确保全面覆盖文件内容。

## 虚拟内存

### Interlude: Memory API

- **内存类型**：C程序运行时涉及栈内存和堆内存。栈内存由编译器自动管理，如在函数中声明`int x;`，编译器会在函数调用时分配空间，函数返回时释放。堆内存则需程序员显式管理，例如使用`malloc()`分配，如`int *x = (int *) malloc(sizeof(int));` ，它先为指针在栈上分配空间，再在堆上请求内存并将地址存于栈上。
- **malloc()调用**：`malloc()`用于在堆上分配内存，需包含`stdlib.h`头文件，传入所需字节数，成功时返回指向新分配空间的指针，失败则返回`NULL`。如`double *d = (double *) malloc(sizeof(double));`利用`sizeof()`操作符获取数据类型大小来请求合适内存。
- **free()调用**：用于释放不再使用的堆内存，如`int *x = malloc(10 * sizeof(int)); free(x);` ，它仅接受`malloc()`返回的指针，且分配区域大小由内存分配库自行跟踪。
- **常见错误**：包括忘记分配内存（如使用未分配的指针导致段错误）、未分配足够内存（可能引发缓冲区溢出）、忘记初始化分配的内存、忘记释放内存（造成内存泄漏）、在使用完之前释放内存（产生悬空指针）、多次释放内存（双释放）以及错误调用`free()`等。例如，`char *dst; strcpy(dst, src);`因`dst`未分配内存会导致段错误。
- **底层OS支持**：`malloc()`和`free()`是库函数，基于系统调用实现。如`brk`和`sbrk`用于改变程序堆的大小，但不建议直接调用。`mmap()`可用于获取内存，能创建匿名内存区域。
- **其他调用**：`calloc()`用于分配内存并初始化为零，可防止未初始化读取错误；`realloc()`用于重新分配内存，如在已分配数组基础上增加空间。

### Mechanism: Address Translation

- **动态（基于硬件）重定位**：早期分时机器引入基于基址和界限寄存器的动态重定位技术。每个CPU有基址和界限寄存器，程序编译时假设加载到地址零，运行时OS设置基址寄存器为程序加载的物理地址。例如，若程序加载到32KB处，基址寄存器设为该值，内存引用时，物理地址 = 虚拟地址 + 基址，界限寄存器用于检查地址是否越界，若越界则引发异常终止进程。
- **硬件支持总结**：硬件需提供特权模式、基址/界限寄存器、地址转换和界限检查功能、更新基址/界限的特权指令、注册异常处理程序的特权指令以及产生异常的能力，以支持地址翻译和内存保护。
- **操作系统问题**：OS在进程创建时为其地址空间分配内存，终止时回收内存，上下文切换时保存和恢复基址 - 界限寄存器对，并提供异常处理程序。例如，在内存管理中，OS通过维护空闲列表来分配和回收内存。

### Segmentation

- **分段：广义的基址/界限**：为解决基址 - 界限寄存器方式的内存浪费问题，提出分段技术。它为地址空间的每个逻辑段（如代码、栈、堆）设置一对基址和界限寄存器，使各段可独立放置在物理内存中。例如，一个64KB物理内存中，可将代码段置于32KB处，大小2KB；堆段置于34KB处，大小3KB等。
- **段的引用判断方式**：硬件通过段寄存器进行地址翻译。常见方式有显式和隐式两种。显式方式如VAX/VMS系统，利用虚拟地址的高位选择段；隐式方式则根据地址形成方式判断所在段，如指令取指时地址在代码段，基于栈或基指针的地址在栈段等。
- **栈的处理**：栈段生长方向与其他段不同，需额外硬件支持来标识其生长方向。在地址翻译时，计算方式会有所不同，如访问栈虚拟地址时，需根据段大小和偏移计算正确的物理地址，并进行界限检查。
- **共享支持**：为节省内存，可在地址空间间共享某些内存段，如代码段。通过添加保护位，硬件可检查访问权限，防止非法访问。例如，将代码段设为只读，可在多个进程间共享，同时保证隔离性。
- **细粒度与粗粒度分段**：多数示例为粗粒度分段，将地址空间划分为较大段。早期如Multics系统支持细粒度分段，允许地址空间包含大量小段，通过段表实现更灵活的内存管理，但也需要更多硬件支持。
- **OS支持**：分段给OS带来新问题，如上下文切换时需保存和恢复段寄存器；段生长或收缩时，OS需提供相应支持；管理物理内存中的空闲空间时，会面临外部碎片问题，可采用紧凑内存或使用自由列表管理算法（如最佳适配、最差适配、首次适配等）来缓解。

### Free-Space Management

- **假设条件**：讨论主要基于用户级内存分配库，假设基本接口为`malloc()`和`free()`，管理的空间为堆，使用自由列表管理空闲空间，主要关注外部碎片问题，且内存分配后不能重定位，分配器管理的区域大小固定。
- **底层机制**：包括分裂和合并操作。分裂用于当请求内存小于空闲块大小时，将空闲块分割；合并则在释放内存时，将相邻空闲块合并为大空闲块。通过在分配内存块前存储头部信息来跟踪大小，如头部包含大小和魔数等信息。在空闲空间内嵌入自由列表，通过特殊方式初始化和管理列表。
- **基本策略**：常见的管理空闲空间策略有最佳适配（返回最接近请求大小的空闲块）、最差适配（返回最大空闲块）、首次适配（找到第一个满足大小的空闲块）和下次适配（在上次查找位置继续查找）。例如，对于一个有10、30和20大小空闲块的列表，分配15大小的内存时，最佳适配选择20的块，最差适配和首次适配选择30的块。
- **其他方法**：隔离列表为特定大小请求设置单独列表，提高分配和释放效率，但需合理分配内存。伙伴分配将内存视为大空间，按需求分割，释放时递归合并，减少内部碎片。此外，还有使用更复杂数据结构（如平衡二叉树等）来提高性能的方法，以及针对多处理器系统的分配器设计。

### Paging: Introduction

- **简单示例与概述**：分页将进程地址空间划分为固定大小的页，物理内存划分为页框。例如，一个64字节的地址空间可分为4个16字节的页，存储在128字节的物理内存中，通过页表记录虚拟页到物理页框的映射关系。地址翻译时，将虚拟地址拆分为虚拟页号和偏移，通过页表查找物理页框号，与偏移组合得到物理地址。
- **页表存储位置**：页表可能非常大，如32位地址空间、4KB页的情况下，每个进程的页表可能达4MB。因此，页表通常存储在内存中，由OS管理，而非特殊的片上硬件。
- **页表内容**：页表通常为线性结构，通过虚拟页号索引。每个页表项包含有效位（指示翻译是否有效）、保护位（控制页面访问权限）、存在位（表示页面在内存还是磁盘）、脏位（记录页面是否被修改）和引用位（跟踪页面是否被访问）等。如x86架构的页表项包含多种标志位和物理页框号。
- **分页的速度问题**：由于页表在内存中，每次内存引用需先访问页表获取翻译信息，这可能导致性能下降。例如，执行`movl 21, %eax`指令时，需先访问页表将虚拟地址转换为物理地址，再访问内存，额外的内存引用增加了开销。
- **内存跟踪示例**：通过一个简单的C代码示例，展示了程序运行时内存访问的情况，包括指令取指和数据访问时的页表访问、虚拟地址到物理地址的转换等过程，以及循环执行时内存访问模式的变化。

### Paging: Faster Translations (TLBs)

- **TLB基本算法**：TLB是地址转换缓存，用于加速地址翻译。硬件在处理虚拟地址时，先检查TLB是否有对应翻译，命中则直接形成物理地址访问内存；未命中则访问页表获取翻译，并更新TLB。例如，访问数组元素时，若TLB命中则快速获取数据，否则需访问页表，导致性能下降。
- **示例：访问数组**：假设一个小的8位虚拟地址空间，有16字节的页，访问数组时会出现TLB命中和未命中的情况。由于数组元素的空间局部性，同一页内的元素访问可能命中TLB，提高访问效率。例如，访问数组中相邻元素时，若首次访问未命中TLB，后续访问同一页内元素则可能命中。
- **谁处理TLB未命中**：有硬件处理和软件（OS）处理两种方式。早期CISC架构多由硬件处理，硬件需知道页表位置和格式；现代RISC架构多由软件处理，TLB未命中时硬件引发异常，OS的TLB未命中处理程序负责查找页表并更新TLB，且需注意避免无限循环的TLB未命中。
- **TLB内容**：TLB通常有32、64或128个条目，为全相联结构。每个条目包含虚拟页号、物理页框号、有效位、保护位等，部分还包含地址空间标识符等。例如，MIPS R4000的TLB支持32位地址空间，有19位虚拟页号、24位物理页框号，还包含全局位、ASID等信息。
- **TLB问题：上下文切换**：上下文切换时，TLB中的翻译仅对当前进程有效，需采取措施确保新进程不使用旧进程的翻译。可通过刷新TLB或添加地址空间标识符（ASID）来解决，ASID可区分不同进程的翻译，减少TLB刷新带来的开销。
- **问题：替换策略**：当TLB需要安装新条目时，需选择替换旧条目，常见策略有LRU（替换最近最少使用的条目）和随机策略等，目的是最小化未命中率，提高性能。

### Paging: Smaller Tables

- **简单解决方案：更大的页**：使用更大的页可减少页表大小，如32位地址空间中，从4KB页变为16KB页，页表大小可减少为原来的四分之一。但大页会导致内部碎片增加，因为应用可能只使用页的部分空间，所以多数系统常用较小页大小。
- **混合方法：分页和分段**：结合分页和分段，为每个逻辑段设置页表，可减少页表内存开销。如Multics系统，通过段基址寄存器指向段的页表，界限寄存器指示页表大小。但该方法仍存在问题，如依赖分段，可能导致外部碎片等。
- **多级页表**：将线性页表转换为类似树的结构，通过页目录跟踪页表的有效页。若页目录项有效，则根据其指向的页表页获取页表项；若无效，则表示该部分地址空间未使用。例如，在一个16KB地址空间、64字节页的示例中，通过多级页表可减少未使用页表空间的分配，提高内存利用率，但TLB未命中时需两次内存访问，增加了复杂性和时间开销。
- **倒置页表**：为每个物理页设置一个页表项，记录使用该页的进程和虚拟页号。查找时需通过哈希表等方式加速，PowerPC是采用这种结构的架构之一，它可显著减少页表占用的内存空间。
- **交换页表到磁盘**：若页表过大无法全部放入内存，部分系统将页表放在内核虚拟内存中，允许在内存压力大时将部分页表交换到磁盘，后续章节将详细讨论相关机制。

### Beyond Physical Memory: Mechanisms

- **交换空间**：为支持大地址空间，OS在磁盘上预留交换空间，用于在内存和磁盘间交换页面。例如，一个4页物理内存和8页交换空间的系统中，多个进程可共享物理内存，部分页面可交换到磁盘，使系统能支持比物理内存更大的虚拟内存。
- **存在位**：在页表项中添加存在位，用于指示页面是否在物理内存中。若存在位为0，表示页面在磁盘上，此时访问该页面会引发页故障，OS的页故障处理程序负责将页面从磁盘换入内存。
- **页故障**：当访问不在物理内存的页面（页故障）时，OS的页故障处理程序运行。它根据页表项中的磁盘地址将页面读入内存，更新页表和TLB，然后重试指令。若内存已满，需选择一个页面换出以腾出空间，这涉及页面置换策略。
- **内存已满时的处理**：内存满时，OS需选择一个页面换出，页面置换策略（如LRU、FIFO等）决定选择哪个页面。选择不当会严重影响程序性能，如使程序运行速度降至磁盘速度。
- **页故障控制流**：硬件在处理内存引用时，根据TLB命中情况和页表项状态进行不同操作。若TLB未命中且页面存在且有效，则更新TLB并重试指令；若页面不存在，则引发页故障。OS的页故障处理程序负责找到空闲物理页，将页面从磁盘读入，更新页表后重试指令。
- **何时进行置换**：多数操作系统通过设置高低水位线来主动管理内存，当可用内存低于低水位线时，后台线程负责释放内存，将页面换出，直到达到高水位线，以避免内存完全耗尽。

### Beyond Physical Memory: Policies

- **缓存管理**：将主内存视为虚拟内存页面的缓存，目标是最小化缓存未命中率，以减少从磁盘读取页面的次数，从而提高平均内存访问时间（AMAT）。AMAT计算公式为`AMAT = TM + (PMiss · TD)`，其中`TM`为访问内存的成本，`TD`为访问磁盘的成本，`PMiss`为缓存未命中的概率。

#### 1. 内存交换机制

- **交换空间**：
  - 磁盘预留区域用于存储内存中不活跃的页面
  - 示例：4页物理内存 + 8页交换空间支持3个进程（图21.1）
- **存在位**：
  - 页表项中的`Present`位标识页面是否在内存
  - 示例：访问`Present=0`的页面触发页故障

#### 2. 页面置换策略

- **最优策略 (OPT)**：
  - 替换未来最远访问的页面（Belady算法）
  - 示例：访问序列0,1,2,0,1,3,0,3,1,2,1中，OPT在第6次访问时替换页2
- **先进先出 (FIFO)**：
  - 简单队列管理，性能较差
  - 示例：相同访问序列中，FIFO在第6次访问时错误替换页0
- **随机策略 (RAND)**：
  - 随机选择置换页，平均性能接近FIFO
  - 示例：在循环顺序访问中表现优于LRU
- **最近最少使用 (LRU)**：
  - **核心思想**：基于局部性原理，替换最久未使用的页面
  - **硬件支持**：
    - 引用位（Use Bit）记录页面访问时间
    - 示例：MIPS R4000的TLB包含访问位（A位）
  - **实现挑战**：
    - 维护全局时间戳或链表开销大
    - 近似方法：时钟算法（CLOCK）
  - **示例**：
    - 访问序列0,1,2,0,1,3,0,3,1,2,1中，LRU在第6次访问时正确替换页2
    - 80-20工作负载中，LRU命中率显著高于FIFO/RAND（图22.7）
- **时钟算法 (CLOCK)**：
  - 环形扫描队列，结合引用位近似LRU
  - 示例：扫描时清除引用位，选择未引用的页置换
- **改进策略**：
  - **2Q算法**：Linux采用的优化LRU，区分活跃/非活跃列表
  - **ARC算法**：自适应缓存替换，平衡扫描抗性

#### 3. 页面置换性能对比

| 策略    | 优点                     | 缺点                     | 典型应用场景               |
|---------|--------------------------|--------------------------|---------------------------|
| OPT     | 理论最优                 | 无法实现                 | 基准测试参考               |
| FIFO    | 实现简单                 | Belady异常、性能差       | 早期系统                   |
| RAND    | 无最坏情况               | 平均性能低               | 研究对比                   |
| LRU     | 利用局部性               | 实现开销大               | 硬件缓存                   |
| CLOCK   | 低开销近似LRU            | 扫描效率低               | 操作系统内核               |
| 2Q      | 区分冷热数据             | 实现复杂度较高           | Linux页面缓存              |

#### 4. 实际系统优化

- **需求调页**：
  - 页面首次访问时才分配物理内存并清零
  - 示例：Linux通过`/dev/zero`实现匿名页的延迟初始化
- **写时复制 (COW)**：
  - 共享页在修改时才复制
  - 示例：`fork()`后父子进程共享内存，写操作时触发复制
- **页面聚类**：
  - 批量写入磁盘提升I/O效率
  - 示例：VAX/VMS将脏页成组写入交换空间

### Complete Virtual Memory Systems

#### 1. VAX/VMS Virtual Memory

- **内存管理硬件**：
  - 32位虚拟地址空间，512字节页，通过段基址寄存器和界限寄存器支持分页与分段的混合模式。
  - 用户地址空间分为P0（用户代码、堆向下增长）和P1（栈向上增长），内核代码位于系统空间S。
  - 示例：P0段基址寄存器指向用户页表，界限寄存器记录页表大小。

- **地址空间结构**：
  - 虚拟地址0不可访问，用于检测空指针引用。
  - 内核代码和数据映射到每个进程的地址空间，方便系统调用数据交互。
  - 示例：VAX/VMS地址空间布局包括无效页、用户代码、堆、栈及内核区域。

- **页面置换策略**：
  - 分段FIFO策略：每个进程有最大驻留集大小（RSS），超出时置换最早进入的页。
  - 全局清洁页和脏页列表：提高置换效率，脏页批量写入磁盘（聚类优化）。
  - 示例：当进程超出RSS时，页面被移至全局列表，其他进程可重用清洁页。

- **优化技术**：
  - 需求调页：页面首次访问时才分配物理内存并清零。
  - 写时复制（COW）：多个进程共享同一物理页，修改时才复制。
  - 示例：`fork()`通过COW快速创建子进程，避免不必要的内存复制。

#### 2. Linux Virtual Memory System

- **地址空间结构**：
  - 32位系统中用户空间（0-0xBFFFFFFF）与内核空间（0xC0000000-0xFFFFFFFF）分离。
  - 内核逻辑地址与物理地址直接映射，用于DMA等需要连续物理内存的场景。
  - 示例：内核逻辑地址0xC0000000对应物理地址0x00000000。

- **页表结构**：
  - x86架构支持4级页表，64位系统使用底部48位地址。
  - 大页支持（2MB/1GB）减少TLB压力，提升大数据集访问效率。
  - 示例：数据库使用大页降低TLB未命中率。

- **页面缓存**：
  - 统一缓存文件数据、元数据和匿名内存。
  - 2Q算法管理缓存，区分活跃和非活跃列表，优化置换策略。
  - 示例：频繁访问的文件页保留在活跃列表，周期性扫描非活跃列表释放空间。

- **安全机制**：
  - NX位（不可执行）防止栈溢出攻击。
  - 地址空间布局随机化（ASLR）动态分配代码、栈和堆的位置。
  - 内核地址空间布局随机化（KASLR）增强内核安全性。
  - 示例：每次运行程序时栈地址不同，增加攻击难度。

- **Meltdown与Spectre攻击**：
  - 利用CPU推测执行漏洞绕过内存保护。
  - 内核页表隔离（KPTI）减少内核数据暴露，缓解攻击风险。

### Summary Dialogue on Memory Virtualization

#### 核心观点总结

1. **虚拟地址与物理地址的透明性**：
   - 用户程序看到的地址是虚拟地址，物理地址由OS和硬件动态映射。
   - 示例：打印指针地址显示的是虚拟地址，无法直接获取物理地址。

2. **TLB的关键作用**：
   - 硬件缓存地址翻译，避免频繁访问页表。
   - 示例：数组访问中，同一页内的连续元素通过TLB命中快速访问。

3. **页表结构的演进**：
   - 从线性页表到多级页表，减少内存占用。
   - 示例：多级页表仅为使用的地址空间部分分配内存。

4. **页面置换策略的实际应用**：
   - LRU等策略需结合硬件支持（如引用位）或软件近似（如时钟算法）。
   - 示例：VAX/VMS通过分段FIFO和全局列表优化置换性能。

5. **内存与安全的权衡**：
   - ASLR和KASLR通过随机化地址空间提高安全性。
   - 示例：栈地址随机化防止缓冲区溢出攻击。

6. **理论与实践的结合**：
   - 理解内存虚拟化机制帮助诊断性能问题（如TLB未命中）。
   - 示例：通过`vmstat`工具观察内存使用和交换行为。

## 同步

### 锁

锁的基本思想不用赘述,我们重点是怎么实现锁,实现一个锁,我们需要几个评价标准:

1. 锁可以完成应该的工作:互斥
2. 公平性
3. 性能

#### 控制中断

只需要在临界区关闭中断即可让一个线程独享临界区:

```C
void lock() {
  DisableInterrupt();
}

void unlock() {
  EnableInterrupt();
}
```

此方法的缺点:

1. 让线程执行特权级指令,不安全
2. 不支持多处理器
3. 关闭中断导致中断丢失,则系统完蛋

这种方法只在操作系统内部可能使用

#### TAS(test and set) 自旋锁

```C
int TestAndSet(int *old_ptr,int new) {
  int old = *old_ptr;
  *old_ptr=new;
  return old;
}
```

在系统中,保证这条指令是原子执行的,用这条指令实现的锁如下:

```C
typedef struct __lock_t {
  int flag;
} lock_t;

void init(lock_t* lock) {
  lock->flag=0;
}

void lock(lock_t* lock) {
  while(TestAndSet(&lock->flag,1))
    ;//spin to wait
}

void unlock(lock_t *lock) {
  lock->flag=0;
}
```

有两个场景:

1. 一个线程运行,调用lock,此时flag为0,lock()函数将lock设置为1,返回0,线程继续运行退出循环,当线程退出临界区,用unlock()将lock置0.
2. 一个线程已经持有锁(lock==1),此时另一个函数调用lock().则旧值仍然保持为1,只要另一个线程仍持有锁,那么此线程的lock()函数就会一直等待

这种锁也被称为自旋锁,在单cpu上需要抢占式调度器否则线程不会放弃cpu

评测:

1. 正确性得到保证
2. 不够公平,可能导致饥饿
3. 性能在单cpu上较差,但是在多cpu上性能尚可

#### CAS(compare and swap)

```C
int CompareAndSwap(int *ptr ,int expected,int new) {
  int actual = *ptr;
  if(actual==expected) {
    *ptr = new;
    return actual;
  }
}
```

基本思想是检测ptr 指向的值是否和expected相等,如果是,更新ptr 所指的值为新值。否则，什么也不做。不论哪种情况，都返回该内存地址的实际值，让调用者能够知道执行是否成功。

```C
void lock(lock_t *lock) {
  while(CompareAndSwap(&lock->flag,0,1)==1)
    ;//spin
}
```

#### 链接加载和条件存储指令

```C
1  int LoadLinked(int *ptr) {
2   return *ptr;
3  }
4
5  int StoreConditional(int *ptr, int value) {
6   if (no one has updated *ptr since the LoadLinked to this address) {
7     *ptr = value;
8     return 1; // success!
9   } else {
10    return 0; // failed to update
11   }
12 }
```

条件存储指令只有在上一次加载的地址在期间没有更新时才会成功,下面是用这两个指令实现的锁:

```C
1  void lock(lock_t *lock) {
2   while (1) {
3     while (LoadLinked(&lock->flag) == 1) // 锁未释放
4       ; // spin until it's zero
5     if (StoreConditional(&lock->flag, 1) == 1)
6       return; // if set-it-to-1 was a success: all done
7          // otherwise: try it all over again
8   }
9  }
10
11 void unlock(lock_t *lock) {
12   lock->flag = 0;
13 }

```

#### 获取并增加

原子地返回特定地址的旧值并让改值自增1

```C
1  int FetchAndAdd(int *ptr) {
2   int old = *ptr;
3   *ptr = old + 1;
4   return old;
5  }
1  typedef struct lock_t {
2   int ticket;
3   int turn;
4  } lock_t;
5
6  void lock_init(lock_t *lock) {
7   lock->ticket = 0;
8   lock->turn = 0;
9  }
10
11 void lock(lock_t *lock) {
12   int myturn = FetchAndAdd(&lock->ticket);
13   while (lock->turn != myturn)
14    ; // spin
15 }
16
17 void unlock(lock_t *lock) {
18   FetchAndAdd(&lock->turn);
19 }

```

注意这种方法中lock使用了ticket和turn两个变量,这种方法保证所有线程都能抢到锁,只要一个线程获得了ticket,那么它最终一定会被调度

#### 性能损失

简单的自旋可能会让线程在获得的时间片内无意义的等待,下面是几个解决方法:

让出cpu:

```C
void lock() {
  while(TestAndSet(&flag,1)==1)
    yield();//让出cpu
}
```

yield是一个原语,线程调用后主动放弃cpu转为其他线程,但是在线程数多的时候,这种方法也会造成性能问题,上下文切换成本很高

---  

使用队列:休眠代替自旋

Solaris提供两个系统调用:park()让调用线程休眠,unpark(threadID)唤醒线程,一个可能的实现方法是:

```C
1  typedef struct lock_t {
2   int flag;
3   int guard;
4   queue_t *q;
5  } lock_t;
6
7  void lock_init(lock_t *m) {
8   m->flag = 0;
9   m->guard = 0;
10   queue_init(m->q);
11 }
12
13 void lock(lock_t *m) {
14   while (TestAndSet(&m->guard, 1) == 1)
15    ; //acquire guard lock by spinning
16   if (m->flag == 0) {
17     m->flag = 1; // lock is acquired
18    m->guard = 0;
19   } else {
20    queue_add(m->q, gettid());
21    m->guard = 0;
22    park();
23   }
24 }
25
26 void unlock(lock_t *m) {
27   while (TestAndSet(&m->guard, 1) == 1)
28    ; //acquire guard lock by spinning
29   if (queue_empty(m->q))
30     m->flag = 0; // let go of lock; no one wants it
31   else
32    unpark(queue_remove(m->q)); // hold lock (for next thread!)唤醒另一个线程,flag仍为1,相当于被唤醒的线程持有锁
33   m->guard = 0;
34 }
```

上述代码有一点小问题:若现在的情况是:一个线程A持有锁,此时队列为空,另一个线程B调用lock(),并执行到第21行,即将睡眠,此时持有锁的线程A调用unlock(),因为此时队列为空,所以lock被设置为0.但是随后线程B进入睡眠,而且永远不会被唤醒
为此引入一个新的系统调用:setpark(),一个线程表明自己马上要park(),如果此时另一个线程被调度,且调用了unpark(),那么后续的park()调用会直接返回而不是睡眠:

```C
1  queue_add(m->q, gettid());
2  setpark(); // new code
3  m->guard = 0;
```

#### 两阶段锁

首先自旋,一段时间后如果仍未获得锁,则睡眠

### 锁的使用

以原子计数器作为例子:

```c
1  typedef struct counter_t {
2    int     value;
3   pthread_mutex_t lock;
4  } counter_t;
5
6  void init(counter_t *c) {
7   c->value = 0;
8   Pthread_mutex_init(&c->lock, NULL);
9  }
10
11 void increment(counter_t *c) {
12  Pthread_mutex_lock(&c->lock);
13   c->value++;
14  Pthread_mutex_unlock(&c->lock);
15 }
16
17 void decrement(counter_t *c) {
18  Pthread_mutex_lock(&c->lock);
19   c->value--;
20  Pthread_mutex_unlock(&c->lock);
21 }
22
23 int get(counter_t *c) {
24  Pthread_mutex_lock(&c->lock);
25   int rc = c->value;
26  Pthread_mutex_unlock(&c->lock);
27   return rc;
28 }
```

这个数据结构没毛病,但问题在于性能太低,一种解决办法是:可扩展计数(Scalable Counting)

#### 可扩展计数(Scalable Counting)

多个局部计数器,一个全局计数器

每个线程有一个局部计数器,当局部计数器的值达到阈值后,将局部计数器的值加到全局计数器上

```C
1  typedef struct counter_t {
2    int      global;     // global count
3    pthread_mutex_t glock;     // global lock
4    int      local[NUMCPUS];  // local count (per cpu)
5    pthread_mutex_t llock[NUMCPUS];  // ... and locks
6    int      threshold;    // update frequency
7  } counter_t;
8
9  // init: record threshold, init locks, init values
10  //   of all local counts and global count
11 void init(counter_t *c, int threshold) {
12   c->threshold = threshold; 13
14   c->global = 0;
15   pthread_mutex_init(&c->glock, NULL);
16
17   int i;
18   for (i = 0; i < NUMCPUS; i++) {
19    c->local[i] = 0;
20    pthread_mutex_init(&c->llock[i], NULL);
21   }
22 }
23
24  // update: usually, just grab local lock and update local amount
25  //   once local count has risen by 'threshold', grab global
26  //   lock and transfer local values to it
27 void update(counter_t *c, int threadID, int amt) {
28  pthread_mutex_lock(&c->llock[threadID]);
29   c->local[threadID] += amt;      // assumes amt > 0
30   if (c->local[threadID] >= c->threshold) { // transfer to global
31    pthread_mutex_lock(&c->glock);
32    c->global += c->local[threadID];
33    pthread_mutex_unlock(&c->glock);
34    c->local[threadID] = 0;
35   }
36  pthread_mutex_unlock(&c->llock[threadID]);
37 }
38
39  // get: just return global amount (which may not be perfect)
40 int get(counter_t *c) {
41  pthread_mutex_lock(&c->glock);
42   int val = c->global;
43  pthread_mutex_unlock(&c->glock);
44   return val; // only approximate!
45 }
```

threshold的值越小,结果越准确,但是效率越低,值越大,并发度越高,但是最终结果越不准确

关于链表和队列与此相似

### 条件变量

有时候线程需要检测到一定条件后才能继续执行,比如父线程需要检查子线程是否执行完毕

```c
1  void *child(void *arg) {
2   printf("child\n");
3   // XXX how to indicate we are done?
4   return NULL;
5  }
6
7  int main(int argc, char *argv[]) {
8   printf("parent: begin\n");
9   pthread_t c;
10   Pthread_create(&c, NULL, child, NULL); // create child
11   // XXX how to wait for child?
12   printf("parent: end\n");
13   return 0;
14 }
```

如果希望看到输出为:
`
parent:begin
child
parent:end
`

一个解决方法:

```C
1  volatile int done = 0;
2
3  void *child(void *arg) {
4   printf("child\n");
5   done = 1;
6   return NULL;
7  }
8
9  int main(int argc, char *argv[]) {
10   printf("parent: begin\n");
11   pthread_t c;
12   Pthread_create(&c, NULL, child, NULL); // create child
13   while (done == 0)
14    ; // spin
15   printf("parent: end\n");
16   return 0;
17 }
```

但是这种方法效率低甚至是错误的

#### 定义和使用

线程使用条件变量来等待一个条件成真,当条件不满足时,将自己加入等待队列来等待条件成真.条件变量有两个函数:`wait()`和`signal()`,具体解释如下:

```C
1  int done = 0;
2  pthread_mutex_t m = PTHREAD_MUTEX_INITIALIZER;
3  pthread_cond_t c = PTHREAD_COND_INITIALIZER;
4
5  void thr_exit() {
6    Pthread_mutex_lock(&m);
7     done = 1;
8    Pthread_cond_signal(&c);
9    Pthread_mutex_unlock(&m);
10  }
11
12  void *child(void *arg) {
13    printf("child\n");
14    thr_exit();
15     return NULL;
16  }
17
18  void thr_join() {
19    Pthread_mutex_lock(&m);
20     while (done == 0)
21        Pthread_cond_wait(&c, &m);
22    Pthread_mutex_unlock(&m);
23  }
24
25  int main(int argc, char *argv[]) {
26     printf("parent: begin\n");
27     pthread_t p;
28     Pthread_create(&p, NULL, child, NULL);
29    thr_join();
30     printf("parent: end\n");
31     return 0;
32  }
```

其中wait()函数有一个参数`&m`,是一个互斥锁,wait()在调用时,释放锁,并让调用线程休眠,当线程被唤醒时(别的线程发信号),它获得锁再返回调用者.

如果代码中没有`done`变量可以吗?

```C
1  void thr_exit() {
2    Pthread_mutex_lock(&m);
3    Pthread_cond_signal(&c);
4    Pthread_mutex_unlock(&m);
5  }
6
7  void thr_join() {
8    Pthread_mutex_lock(&m);
9     Pthread_cond_wait(&c, &m);
10    Pthread_mutex_unlock(&m);
11  }
```

不行!若子线程立即执行`thr_exit()`,则发信号时没有在此条件变量上等待的线程,父线程调用`wait()`后会卡在那儿

如果不加锁?

```C
1  void thr_exit() {
2   done = 1;
3   Pthread_cond_signal(&c);
4  }
5
6  void thr_join() {
7   if (done == 0)
8     Pthread_cond_wait(&c);
9  }
```

当父线程检测到done=0后,切换到子进程,子进程发送信号,同样父进程会卡住.

> 始终保证在调用wait()和signal()时持有锁

#### 生产者消费者(有界缓冲区)

> 信号量实现见[信号量生产者消费者](#生产者消费者问题信号量解决)

一个缓冲区,一个或多个生产者往缓冲区中放数据,一个或多个消费者从缓冲区中取数据.

要注意的点是:

1. 同一时间只有一个生产者可以写入缓冲区
2. 同一时间只有一个消费者可以消费缓冲区
3. 只有缓冲区还有空位时生产者才可以写入缓冲区
4. 只有缓冲区中有内容时消费者才可以读出内容

先假设缓冲区就是一个变量:

```C
int buffer;
int count=0;

void put(int value) {
  assert(count==0);
  count=1;
  buffer=value;
}

void get(int value) [
  assert(count==1);
  count=0;
  return buffer;
]
```

一个不太对的实现:注意这里是if实现

```C
1  int loops; // must initialize somewhere...
2  cond_t cond;
3  mutex_t mutex;
4
5  void *producer(void *arg) {
6     int i;
7     for (i = 0; i < loops; i++) {
8         Pthread_mutex_lock(&mutex);     // p1
9         if (count == 1)          // p2
10            Pthread_cond_wait(&cond, &mutex); // p3
11         put(i);              // p4
12         Pthread_cond_signal(&cond);     // p5
13         Pthread_mutex_unlock(&mutex);    // p6
14    }
15  }
16
17  void *consumer(void *arg) {
18     int i;
19     for (i = 0; i < loops; i++) {
20         Pthread_mutex_lock(&mutex);     // c1
21         if (count == 0)          // c2
22            Pthread_cond_wait(&cond, &mutex); // c3
23         int tmp = get();          // c4
24         Pthread_cond_signal(&cond);     // c5
25         Pthread_mutex_unlock(&mutex);    // c6
26        printf("%d\n", tmp);
27    }
28  }

```

当仅有一个生产者和一个消费者时,这个方案没问题,但是当有多个时,会有问题,与count的if判断有关:

假设有两个消费者:C1和C2,一个生产者P1.C1先运行,发现缓冲区为空后进入睡眠,接着P1运行,填充缓冲区后发出信号,此时C1从等待状态变为就绪状态,但是C2先运行,并且消费了缓冲区内的所有内容,接着C1运行,发现缓冲区内为空,assert()断言触发,发生错误.

为此,我们把`if`修改为`while`即可:

```c
1  int loops; // must initialize somewhere...
2  cond_t cond;
3  mutex_t mutex;
4
5  void *producer(void *arg) {
6     int i;
7     for (i = 0; i < loops; i++) {
8         Pthread_mutex_lock(&mutex);     // p1
9         while (count == 1)          // p2
10            Pthread_cond_wait(&cond, &mutex); // p3
11         put(i);              // p4
12         Pthread_cond_signal(&cond);     // p5
13         Pthread_mutex_unlock(&mutex);    // p6
14    }
15  }
16
17  void *consumer(void *arg) {
18     int i;
19     for (i = 0; i < loops; i++) {
20         Pthread_mutex_lock(&mutex);     // c1
21         while (count == 0)          // c2
22            Pthread_cond_wait(&cond, &mutex); // c3
23         int tmp = get();          // c4
24         Pthread_cond_signal(&cond);     // c5
25         Pthread_mutex_unlock(&mutex);    // c6
26        printf("%d\n", tmp);
27    }
28  }
```

> 总是使用while循环检查条件变量!

但是代码仍有一定的问题:

两个消费者先运行,C1和C2都进入了睡眠,接着P1生产数据后唤醒一个进程C1,P1进入睡眠.注意此时:`睡眠的进程有P1和C2,都等待着同一个cond信号`,那么当C1唤醒一个等待线程时应该唤醒谁?若唤醒C2,则C2发现count为0,又进入睡眠.那么此时三个线程都会进入睡眠!!!

对于这个单值缓冲区的解决,可以使用两个条件变量

```C
cont_t empty,fill;
mutex_t mutex;
int count;

void * producer(void *arg) {
  int i;
  for(i=0;i<loops;i++) {
      Pthread_mutex_lock(&mutex);
      while(count==1)
        Pthread_cont_wait(&empty,&mutex);
      put(i);
      Pthead_cont_signal(&fill);
      Pthead_mutex_unlock(&mutex);
  }
}

void * consumer(void * arg) {
  int i;
  for(i=0;i<loops;i++) {
    Pthead_mutex_lock(&mutex);
    while(count==0)
      Pthread_cont_wait(&fill,&mutex);
    int temp = get();
    Pthread_cont_signal(&empty);
    Pthread_mutex_unlock(&mutex);
  }
}
```

为支持多缓冲区槽位,有以下的解决方案:

```c
int buffer[MAX];
int fill_ptr = 0;
int use_ptr = 0 ;
int count=0;
cond_t empty,fill;
mutex_t mutex;

void put(int value) {
  buffer[fill_ptr]=value;
  fill_ptr=(fill_ptr+1)%MAX;
  count++;
}

int get() {
  int tmp = buffer[use_ptr];
  use_ptr = (use_ptr+1)%MAX;
  count--;
  return tmp;
}

void * producer() {
  int i;
  for(i=0;i<loops;i++) {
    Pthread_mutex_lock(&mutex);
    while(count==MAX) 
      Pthead_cont_wait(&empty,&mutex);
    put(i);
    Pthread_cont_signal(&fill);
    Pthead_mutex_unlock(&mutex);
  }
}

void * consumer() {
  int i;
  for(i=0;i<loops;i++) {
    Pthread_mutex_lock(&mutex);
    while(count==0)
      Pthread_cont_wait(&fill,&mutex);
    int tmp = get();
    Pthread_cont_signal(&empty);
    Phtread_mutex_unlock(&mutex);
    printf("%d/n",tmp);
  }
}
```

#### 覆盖条件

假设一个内存分配需求,已经有一些线程等着分配内存,但是需求不同,现在有空闲内存后,分配内存的线程应该唤醒谁?假设C1等50B,C2等100B,现在有75空闲,若唤醒C2,则没有用.这造成无意义的性能浪费.

解决办法是进行信号广播,将信号传递给所有等待线程,但是这种情况性能有影响,而且最好不要用.

### 信号量

#### 定义

几个系统调用:

```c
#include<semaphore.h>
sem_t s;
sem_init(&s,0,1);//初始化,0表示该信号量在同一个进程中使用,1表示初始值为1
sem_wait();//P
sem_post();//V
```

---  

PV的操作:

```c
//P
int sem_wait(sem_t *s) {
  s-=1;
  if (s<0) 
    wait();//阻塞
}

int sem_post(sem_t *s) {
  s+=1;
  if thread waiting,wake one
}
```

信号量的性质:信号量小于零时绝对值为等待的线程数

#### 二进制信号量(锁)

```C
sem_t m;
sem_init(&m,0,1);

sem_wait(&m);
critical section
sem_post(&m);

```

#### 信号量for ordering

在需要按照一定顺序执行的程序中,信号量也可以起到作用:

```c
sem_t s;

void child() {
  printf("hello from child!");
  sem_post(&s);
  return NULL;
}

int main() {
  sem_init(&s,0,0);//初值设置为0
  printf("begin main");
  pthread_t c;
  pthread_create(&c,NULL,child,NULL);
  sem_wait(&s);
  printf("end main");
  return 0;
}
```

信号量初值的设置:考虑希望给出多少资源,例如lock,希望初始化后立即被拥有,所以设置为1,在order中,由于不需要谁来获得资源,所以设置为0

#### 生产者消费者问题(信号量解决)

```c
int buffer[MAX];
int fill = 0;
int use = 0;

void put(int value) {
  buffer[fill] = value; // Line F1
  fill = (fill + 1) % MAX; // Line F2
}

int get() {
  int tmp = buffer[use]; // Line G1
  use = (use + 1) % MAX; // Line G2
  return tmp;
}

```

一个有问题的实现:

```c
1 sem_t empty;
2 sem_t full;
3
4 void *producer(void *arg) {
5   int i;
6   for (i = 0; i < loops; i++) {
7     sem_wait(&empty); // Line P1
8     put(i); // Line P2
9     sem_post(&full); // Line P3
10  }
11 }
12
13 void *consumer(void *arg) {
14  int tmp = 0;
15  while (tmp != -1) {
16    sem_wait(&full); // Line C1
17    tmp = get(); // Line C2
18    sem_post(&empty); // Line C3
19    printf("%d\n", tmp);
20  }
21 }
22
23 int main(int argc, char *argv[]) {
24  // ...
25  sem_init(&empty, 0, MAX); // MAX are empty
26  sem_init(&full, 0, 0); // 0 are full
27  // ...
28 }
```

上述代码在MAX=1时工作的很好,但是当MAX大于1后,即有多生产者多消费者,当进程A即将执行put()时,被打断,进程B进入临界区完成put(),然后A完成put(),则出现了race condition.
我们需要互斥锁,一个实现:

```c
1 void *producer(void *arg) {
2   int i;
3   for (i = 0; i < loops; i++) {
4     sem_wait(&mutex); // Line P0 (NEW LINE)
5     sem_wait(&empty); // Line P1
6     put(i); // Line P2
7     sem_post(&full); // Line P3
8     sem_post(&mutex); // Line P4 (NEW LINE)
9   }
10 }
11
12 void *consumer(void *arg) {
13  int i;
14  for (i = 0; i < loops; i++) {
15    sem_wait(&mutex); // Line C0 (NEW LINE)
16    sem_wait(&full); // Line C1
17    int tmp = get(); // Line C2
18    sem_post(&empty); // Line C3
19    sem_post(&mutex); // Line C4 (NEW LINE)
20    printf("%d\n", tmp);
21  }
22 }
```

上述代码会发生死锁:消费者C先获得锁,此时缓冲区为空,消费者进入sleep,生产者运行,但是锁被消费者占有,所以出现死锁.

正确的实现:

```c
void* producer(void* arg){
  int i;
  for(i=0;i<loops;i++) {
    sem_wait(&empty);
    sem_wait(&mutex);
    put(i);
    sem_post(&mutex);
    sem_post(&full);
  }
}

void* consumer(void* arg) {
  int i;
  for(i=0;i<loops;i++) {
    sem_wait(&full);
    sem_wait(&mutex);
    int temp=get(i);
    sem_post(&mutex);
    sem_post(&empty);
    printf("%d\n",temp);
  }
}
```

#### 读者写者问题

读和写是互斥的
同一个时间段只有一个写者
当第一个读者获得读者锁时,他同时获得写者锁,保证了之后可以有其他读者,但是当读者不为0时,写者不可写

```C
typedef struct _rwlock_t {
  sem_t lock;
  sem_t writelock; //allow one writer/many readers
  int reader; //how many reader there
} rwlock_t;

void rw_lock_init(rwlock_t* rw) {
  rw->reader = 0;
  sem_init(&rw->lock,0,1);
  sem_init(&rw->writelock,0,1);
}

void rwlock_acquire_readlock(rwlock* rw) {
  sem_wait(&rw->lock);
  rw->reader++;
  if(rw->readers == 1)
    sem_wait(&rw->writelock);
  sem_post(&rw->lock);
}

void rwlock_release_readlock(rwlock* rw) {
  sem_wait(&rw->lock);
  rw->reader--;
  if(rw->reader==0)
    sem_post(&rw->writelock);
  sem_post(&lock);
}

void rwlock_acquire_writelock(rwlock* rw) {
  sem_wait(&rw->writelock);
}

void rwlock_release_writelock(rwlock* rw) {
  sem_post(&rw->writelock)
}
```

问题是写者可能陷入饥饿,解决方法是设置当有写者在等待时,读者不再增加

#### 哲学家进餐问题

五个哲学家坐圆桌,有五把叉子,每个哲学家需要两把叉子才能吃法,哲学家的状态会在思考和吃饭之间切换,即:
`
while(1) {
  think();
  get_fork();
  eat();
  put_fork();
}
`

我们的目标是:设计get_fork()和put_fork()函数,使的不会有哲学家挨饿,而且同一时间有尽可能多的哲学家进餐.
为此我们引入两个辅助函数:

```c
int left(int p) {return p;}
int rigth(int p) {retutn (p+1)%5;}
```

一个简单的实现如下:

```C
1 void get_forks(int p) {
2   sem_wait(&forks[left(p)]);
3   sem_wait(&forks[right(p)]);
4 }
5
6 void put_forks(int p) {
7   sem_post(&forks[left(p)]);
8   sem_post(&forks[right(p)]);
9 }
```

但是会陷入每个哲学家都拿着左手叉子从而导致饥饿的问题,一个简单的解决方法是:让一个哲学家拿叉子的顺序不同:

```C
1 void get_forks(int p) {
2   if (p == 4) {
3     sem_wait(&forks[right(p)]);
4     sem_wait(&forks[left(p)]);
5   } else {
6       sem_wait(&forks[left(p)]);
7       sem_wait(&forks[right(p)]);
8   }
9 }
```

另一个解决方法是设置一个仲裁信号量,限制同一时间最多只有四个哲学家进餐
或者规定哲学家的进餐优先级,或者可以引入随机延迟

#### 线程阈值

用信号量设置同时可以进行任务的线程最大数值

#### 信号量的底层实现

一个简单的实现如下:

```c
typedef struct _Zem_t {
  int value;
  pthread_cond_t cond;
  pthread_mutex_t lock;
} zem;

void zem_init(zem_t *s,int value) {
  s->value=value;
  cond_init(&s->cond);
  lock_init(&s->lock);
}

void zem_wait(zem_t* s) {
  mutex_lock(&s->lock);
  while(s->value<0) {
    cond_wait(&s->cond,&s->lock);
  }
  s->value--;
  mutex_unlock(&s->lock);
}

void zem_post(zem_t* s) {
  mutex_lock(&s->lock);
  s->value++;
  cond_signal(&s->cond);
  mutex_unlock(&s->lock);
}
```

### 同步bugs || 非死锁/死锁

#### 非死锁

##### 原子性违反

需要原子操作的场景没有被原子性保护

示例:

```C
1 Thread 1 ::
2 if (thd->proc_info) {
3  fputs(thd->proc_info,...);
4}

5 Thread 2 ::
6 thd->proc_info = NULL;
```

线程1通过检查后线程2将指针设为空指针,线程1再次执行,发生空指针错误

修复:加上锁即可

```C
pthread_mutex_t proc_info_loc = PHTREAD_MUTEX_INITIALIZER;

Thread 1 ::
pthread_mutex_lock(&proc_info_loc);
if(thd->proc_info) {
  fputs(thd->proc_info,...);
}
pthread_mutex_unlock(&proc_info_loc);

Thread 2 ::
phtread_mutex_lock(&proc_info_loc);
thd->proc_info = NULL;
pthread_mutex_unlock(&proc_info_loc);
```

##### 执行顺序违反

本应该按照某种顺序执行的操作没有按照这种顺序执行

```C
Thread 1::
void init() {
  mThread = PR_CreateThread(mMain,...);
}

Thread 2::
void mMain() {
  mState = mThread->State;//这里假设mThread已经初始化,但事实可能并非如此
}
```

这里因为涉及到顺序,也就是条件,所以可以用条件变量解决

```c
pthread_mutex_t mtLock = PTHREAD_MUTEX_INITIALIZER;
pthread_cond_t mtCond = PTHREAD_COND_INITIALIZER;
int mtInit = 0;

Thread 1 ::
void init() {
  mThread = PR_CreateThread(mMain,...);

  pthread_mutex_lock(&mtLock);
  mtInit = 1;
  pthread_mutex_signal(&mtCond);
  pthread_mutex_unlock(&mtLock);
}

Thread2 ::
void mMain() {
  pthread_mutex_lock(&mtLock);
  while(mtInit==0) {
    pthread_cond_wait(&mtCond);
  }
  phread_mutex_unlock(&mtLock);
  mState = mThread->State;
}
```

大部分的同步问题来自于非死锁bug

#### 死锁

经典模型:

`
Thread 1 :                  Thread 2 :
pthread_mutex_lock(L1);     pthread_mutex_lock(L2);
pthread_mutex_lock(L2);     pthread_mutex_lock(L1);
`

bug来自于:线程一获得L1后,线程2执行并获得L2,这时线程1持有L1,线程2无法继续执行,线程1由于线程2获得L2,也无法继续执行.陷入死锁

只要两个线程获取锁的顺序一致就可以了,那现实软件为什么会出现死锁bug呢?一方面因为code base太大了,另一方面因为封装对外隐蔽了实现细节.

##### 死锁的条件

- 互斥:有线程互斥的数据
- 占有并等待:一个线程占有一个资源并等待另一个资源到来后才能继续执行
- 非抢占式:资源无法从线程中强制移除
- 循环等待:线程之间存在资源的循环等待

##### 避免死锁

循环等待

最好的是对锁规定获得顺序,在大型系统中不好做到的话,可以采用偏序

tips:
强制按顺序获得锁:
假设有一个函数:`do something(mutex t *m1, mutex t *m2)`由于调用者传入的锁的顺序不一样(`(L1,L2) / (L2,L1)`),所以可以采用下面的基于`地址`的方法来对获得锁的顺序进行调整:

```C
if (m1 > m2) { // grab in high-to-low address order
pthread_mutex_lock(m1);
pthread_mutex_lock(m2);
} else {
pthread_mutex_lock(m2);
pthread_mutex_lock(m1);
}
// Code assumes that m1 != m2 (not the same lock)
```

---  

占有并等待

可以通过一次性获得所有锁来完成:

```C
pthread_mutex_lock(prevention);//begin
pthread_mutex_lock(L1);
pthread_mutex_lock(L2);
...
pthread_mutex_unlock(prevention);//end
```

问题:

1. 函数调用者需要知道函数内部需要获得哪些锁,破坏了封装性
2. 降低了并行度,因为锁通常是按需获得,这样不同线程可以更好的协作

---  

非抢占式

引入`trylock`机制

```C
top:
  pthread_mutex_lock(L1);
  if(pthrea_mutex_trylock(L2)==0) {
    pthread_mutex_unlock(L1);
    goto top;
  }
```

缺点:

引入`livelock`问题

- 活锁是指两个线程都在不断尝试获取锁，但每次都失败的情况。
- 例如：
  - 线程 T1 获取 L1 后尝试获取 L2，发现 L2 被 T2 持有，于是释放 L1。
  - 线程 T2 获取 L2 后尝试获取 L1，发现 L1 被 T1 持有，于是释放 L2。
  - 两个线程不断重复这一过程，虽然它们都没有阻塞，但也没有取得任何进展。
- 解决活锁的方法:
  - 在每次重试之前引入随机延迟（例如 sleep()），从而降低线程之间的干扰概率。

破坏封装

需要回退到起点意味着释放获得的资源,不止是锁,例如:

```C
pthread_mutex_lock(L1);
void* memory = malloc(1024); // 分配内存
if (pthread_mutex_trylock(L2) != 0) {
    free(memory); // 释放内存
    pthread_mutex_unlock(L1); // 释放锁
    goto top; // 回到起点
}
```

---  

互斥

采用CAS(compare-and-swap),实现无锁同步
需要三个值:地址,期望值,新值,
具体过程:
比较地址处值和期望值,若相等,则将地址值更新为新值,返回成功标记1,否则返回失败标记0

```c
int compare_and_swap(void* address,T expected,T new) {
  if(*address == expected) {
    *address = new;
    return 1;
  }
  return 0;
}
```

下面是一段使用锁的代码:

```c
void AtomicIncrement(int *value,int amount) {
  phtread_mutex_lock(&lock);
  *value+=amount;
  phtread_mutex_unlock(&lock);
}
```

下面是他的无锁实现:

```c
void AtomicIncrement(int *value,int amount) {
  do {
    int old = *value;
  } while (Compare_and_swap(value,old,old+amount));
}
```

---  

调度

除了prevention死锁,我们可以选择avoidance死锁

简单来说,将需要获得同样的资源的线程放到一个cpu上顺序执行,这样保证了不会出现互斥,具体见:

![alt text](./附件/image.png)

---  

发现并恢复

允许死锁发生,在必要时重启系统
