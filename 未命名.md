### 现状与瓶颈分析

- 当前缓存实现特征
  - 分片 `unordered_map<Key=({segment}, wkb_ptr, wkb_size)>`，命中返回 `std::shared_ptr<const Geometry>`。
  - 命中与未命中路径均含分片互斥量、哈希计算、哈希桶访问、引用计数调整、统计原子计数等操作。
  - 命中热路径在每个元素上执行，位于最内层循环。

- 命中路径开销拆解（单次命中的典型量级，64 位 x86，编译器 O2/O3，缓存良好情况）
  - 互斥锁加解锁（无争用）：20–60 ns（取决于平台实现与频率缩放）
  - 哈希计算（两次 pointer/size 哈希 + 混合）：5–20 ns
  - 哈希桶访问与指针比较：10–40 ns（易受微架构与数据局部性影响）
  - `shared_ptr` 引用计数增减（命中返回 + 出作用域）：10–30 ns（跨核共享场景可更高）
  - 原子统计计数（命中/未命中/拒绝）：5–20 ns（共享缓存线时会劣化）
  - 合计估算：50–170+ ns（低争用场景）；在真实并发场景中，锁竞争与缓存线抖动会将总开销轻易推升到 200–400 ns

- 与直接构造对比
  - 直接构造测得约 160 ns/次
  - 命中路径在工程真实负载下很难稳定低于 160 ns，尤其在并发+热点段下会显著高于 160 ns
  - 结论：以 `unordered_map + 互斥锁 + shared_ptr` 的设计，命中路径常态值不具备压过直接构造的确定性收益，缓存“命中”反而可能变慢

- 典型造成性能下降的根因
  - 每次命中都需要互斥锁，破坏 CPU 管线与可预测性，且在热点 shard 上容易造成竞争
  - `unordered_map` 链式散列访问的内存局部性差，命中路径易发生 L2/L3 访存
  - `shared_ptr` 的原子引用计数造成跨核共享缓存线写入
  - 命中统计的原子计数进一步放大缓存线抖动
  - 缓存键使用指针+长度虽是 O(1) 身份判等，但仍需要哈希与哈希桶寻址

### 缓存命中 vs 直接构造的量化对比

- 直接构造：≈ 160 ns
- 现有缓存命中（低争用理想值）：≈ 120–200 ns
- 现有缓存命中（中等并发）：≈ 200–400 ns
- 现有缓存命中（高并发/热点 shard）：≈ 400 ns 以上

在多数真实并发场景中，缓存命中开销 ≥ 直接构造开销，导致整体性能下降。

### 全局数组缓存方案评估

- 可行性分析
  - 思路：为每个段或每个数据块分配一个与行数等长的“槽位数组”，每槽存放已解码的 `Geometry*`；命中 O(1) 无哈希、无锁
  - 优点：命中路径仅是两次指针算术 + 一个原子读，局部性极佳；构造后常驻直到段销毁，无淘汰抖动
  - 难点：执行 lambda 当前未显式传入“全局行号/块内偏移”，仅有数据指针；需要将“当前块的起始位置/偏移”传给 lambda，或引入一次性“块基指针→槽数组”的查找
  - 内存占用：O(N) 指针/对象，N 为段内行数；如果 `Geometry` 占用很大，可能超内存预算。可仅缓存“热点段/热点块”或设置段级上限

- 并发问题分析
  - 多线程同时解码同一槽位的竞争
  - 多线程同时创建某块的槽数组映射的竞争
  - 段销毁与缓存释放的生命周期一致性

- 线程安全解决方案（至少两种）
  - 方案 A：每槽位使用 `std::atomic<Geometry*>` + CAS
    - 命中：`Geometry* p = slots[idx].load(memory_order_acquire)`；若非空直接用
    - 未命中：本地解码 `g = new Geometry(...)`，`CAS(nullptr -> g)`；CAS 失败则销毁 `g` 或转交所有权
    - 优点：无锁、每元素极细粒度、命中路径极快
    - 缺点：释放需在段销毁时统一回收（不支持中途逐出）
    - 适用：读多写少、对象生命周期与段一致的场景
  - 方案 B：每块粒度互斥锁 + 槽数组懒初始化 + 槽位普通指针
    - 第一次访问某块时加锁创建 `std::vector<Geometry*> slots(chunk_size, nullptr)`；解码时在锁内检查插槽、在锁外解码、回锁写入
    - 优点：实现简单，易于控制内存
    - 缺点：高并发下该块锁成为瓶颈；但每块常驻后命中无需加锁
    - 适用：块粒度足够分散、并发访问集中在不同块

（可选）方案 C：线程局部存储（TLS）小型直接映射缓存
  - 为每线程维护固定容量（如 64/128）的小型指针→对象数组（或 2/4 路组相联），最近访问元素命中概率高
  - 优点：无锁，命中路径非常低；与段/块数组结合时可进一步降低访问延迟
  - 缺点：容量有限；线程间不共享，跨线程命中率为 0

### 优化方案设计

-

- 方案二：自适应缓存（仅缓存“重/慢对象”）+ TLS L1 + 扁平哈希
  - 数据结构
    - TLS L1：每线程小型直接映射缓存（例如 64 槽），key=`wkb_ptr`，value=`Geometry*`
    - L2：段级 `robin_hood::unordered_flat_map` 或 `absl::flat_hash_map`，key=`(segment, wkb_ptr)`，value=`Geometry*`
  - 缓存策略
    - 仅当 `wkb_size >= threshold`（如 128/256 字节）时才尝试写入 L2；小对象直接构造不缓存
    - 命中顺序：先查 TLS L1（无锁 O(1) 极低开销），未命中再查 L2（无链表、开地址，局部性好）
    - 对象生命周期：直到段销毁，不用 `shared_ptr`，返回裸指针只读
  - 并发控制
    - TLS 无锁；L2 使用分片自旋锁或每桶自旋锁，读侧在绝大多数命中不加锁（只读结构可使用读侧无锁+发布写）
  - 预期性能
    - TLS 命中：≈ 10–30 ns
    - L2 命中：≈ 60–120 ns（开地址 + 局部性 + 无引用计数 + 无统计原子）
    - 对比现状：命中路径 < 160 ns；缓存门槛避免小对象“越缓存越慢”

- 方案三：保守策略（最小改动）
  - 数据结构：沿用现有，但做以下改造
    - 移除命中/未命中等原子统计的每次累加，改为采样统计（如 1/1024 采样）或延迟聚合
    - 命中返回改为裸指针或 `intrusive_ptr`，避免 `shared_ptr` 频繁原子计数
    - 分片锁改为 `std::atomic_flag` 自旋短临界区，或 RCU 风格读侧无锁
    - 增加 size-based 阈值，仅缓存大 WKB
  - 预期性能
    - 低并发下可接近 120–180 ns；中高并发仍可能被锁竞争拉高
  - 风险
    - 改动小但收益有限；并发场景下难以保证稳定低于 160 ns

### 性能评估与对比

- 基线（直接构造）：≈ 160 ns/次
- 现有缓存命中：≈ 200–400+ ns（并发下更差）
- 方案一（按块槽数组 + 每槽 CAS）
  - 命中：≈ 20–60 ns
  - 未命中：≈ 160 ns + 若干纳秒
  - 相比现状：命中提升 3–10 倍；相比直接构造：命中至少 2–8 倍更快
- 方案二（自适应缓存 + TLS L1 + 扁平哈希）
  - TLS 命中：≈ 10–30 ns；L2 命中：≈ 60–120 ns
  - 未命中：≈ 160 ns（直接构造）或 L2 插入少量额外开销
  - 相比现状：命中提升 2–10 倍；相比直接构造：命中 1.3–16 倍更快
- 方案三（保守改造）
  - 命中：≈ 120–180 ns（低并发），≈ 180–300 ns（中并发）
  - 相比现状：小幅好转；相比直接构造：收益不稳定

### 推荐结论

- 若允许对执行层做小幅接口增强（传递块内偏移/块 id），优先落地“方案一（按块槽数组 + 每槽 CAS）”
  - 命中路径可稳定压到 20–60 ns，远低于 160 ns
  - 无哈希、无锁、极强局部性，顺序扫描与重复查询下命中率接近 100%
  - 段销毁统一释放对象，生命周期简单

- 若不便改动执行接口，落地“方案二（自适应缓存 + TLS L1 + 扁平哈希）”
  - 通过 size-based 门槛避免“小对象越缓存越慢”
  - TLS L1 覆盖高重复率的最近访问，降低 L2 压力
  - L2 使用开地址扁平哈希 + 裸指针，移除 `shared_ptr` 与统计原子，命中低于 120 ns 可期

- 辅助建议
  - 将统计改为采样，或仅在后台汇总，避免原子热点
  - 按段启用/禁用缓存，通过命中率与对象平均大小动态决策
  - 对于极大 WKB（> N KB），强制缓存以确保收益；对于极小 WKB，默认不缓存

以上方案在高并发下能显著降低命中路径的固定开销，确保“命中收益 > 缓存开销”，从而修复“启用缓存反而变慢”的问题。


## apply

 方案一：段内“按块槽数组 + 每槽原子 CAS”（推荐）
  - 数据结构
    - 段级：`unordered_map<chunk_base_ptr, unique_ptr<SlotArray>>`（仅每块一个键，非每行）；`SlotArray = vector<atomic<Geometry*>>`
    - 槽位：`atomic<Geometry*>`，初始化为 `nullptr`
  - 缓存策略
    - 第一次访问某块：懒创建 `SlotArray`（一次 map 查找；可用 `robin_hood::unordered_map`/`absl::flat_hash_map` 提升局部性）
    - 命中：atomic load 直接返回
    - 未命中：构造后 CAS 写入；CAS 失败则丢弃本地对象或复用已有
    - 删除/更新：直到段销毁统一释放，无中途逐出
  - 并发控制
    - 槽位级 CAS 无锁；仅在“创建块槽数组”时使用块级互斥
  - 预期性能
    - 命中路径：≈ 20–60 ns（atomic 读 + 指针算术）
    - 未命中路径：≈ 160 ns（构造）+ CAS 几 ns
    - 与现有相比：命中明显低于 160 ns，收益确定
  - 适配性
    - 需要在执行 lambda 能拿到“块内偏移/基指针”，便于 O(1) 定位槽位；若当前接口没有，需要最小扩展在 `ProcessDataChunks` 传入起始偏移或块 id

- 方案 b（推荐）：块ID映射（一次/次批，O(log C)）+ 槽位 O(1)

- 思路：

- 段级预建/懒建“块范围索引表”：有序数组 ranges = [{begin_ptr, end_ptr, base_ptr, chunk_id, base_row_index}]，按 begin_ptr 排序，覆盖该字段的全部块。

- 每次 execute_sub_batch(data, ..., size, ...) 时，先用 data 做一次二分搜索确定所在块（O(log C)，C 为块数；sealed 非分块时 O(1)）。

- 命中后得到该块的 base_row_index 与 base_ptr；本次循环内的槽下标为 slot_idx = base_row_index + local_offset，local_offset 即 i（因为本次 sub-batch 内存连续且属于同一块切片）。

- 槽数组为 vector<atomic<Geometry*>>，长度等于块内行数。读取：p = slots[slot_idx].load(acquire)；若空则本地解码后 CAS 写回。

- 性能：

- 每次 sub-batch 仅一次二分搜索（C 通常不大，或 sealed=1），摊到每元素≈可忽略；元素访问 O(1) 原子读+指针算术，命中≈20–60ns。

- 并发：

- 槽位用 CAS 无锁；仅在“首次创建该块的槽数组”使用块级互斥。

- 适配性：

- 不改 ProcessDataChunks；lambda 捕获 this 即可访问 segment_，索引表可挂载在段级缓存结构中。